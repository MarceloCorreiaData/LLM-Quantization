{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24. Zephyr 7B Beta GPTQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,2,3'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1,2,3'\n",
    "os.environ.get('CUDA_VISIBLE_DEVICES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, LlamaTokenizerFast, MistralForCausalLM, pipeline\n",
    "import torch\n",
    "\n",
    "# Load LLM and Tokenizer\n",
    "model_path = '/var/ontologia/Servicos/ACS_LLMS/server/models/zephyr-7b-beta-gptq'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\", trust_remote_code=False, revision=\"main\")\n",
    "\n",
    "# Create a pipeline\n",
    "pipe = pipeline(model=model, tokenizer=tokenizer, task='text-generation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################################  COMPREENSÃO E GERAÇÃO DE TEXTO  ############################################\n",
    "############################################  AVALIAÇÃO DA SEMÂNTICA E SINTAXE EM PT-BR  ############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Os investimentos em renda fixa são considerados uma das opções mais seguras do mercado financeiro e são especialmente atraentes para investidores com perfil conservador. Esses investimentos são compostos principalmente por títulos de dívida, seja pública ou privada. No Brasil, muitos bancos, incluindo o Banco do Brasil, oferecem uma variedade de opções de investimento em renda fixa. Esses investimentos têm como característica principal o retorno previsível, e o rendimento, na maioria das vezes, é acordado no momento da aplicação.\n",
      "- **CDB (Certificado de Depósito Bancário)**: O CDB pode ser encontrado em 3 modalidades: prefixada, pós-fixada e progressiva. Enquanto o CDB prefixado tem um rendimento acordado no ato da aplicação, o pós-fixado e o progressivo são atrelados ao CDI, com o último tendo sua taxa definida com base no tempo de permanência da aplicação. Apesar do prazo de vencimento, o CDB pós-fixado e o progressivo podem ser resgatados a qualquer momento. É adequado para investidores que buscam mais rentabilidade do que a poupança e estão dispostos a abrir mão da liquidez diária. \n",
      "- **LCI e LCA**: Ambos são títulos emitidos por bancos para financiar respectivamente o setor imobiliário e agrícola. São ideais para investidores que buscam isenção de Imposto de Renda e desejam investir em setores específicos da economia, como imobiliário ou agrícola. \n",
      "- **Títulos do Tesouro Direto**: Existem diversas modalidades, como o Tesouro Selic, ideal para reserva de emergência; Tesouro Prefixado, para quem acredita que a taxa de juros e a inflação vão cair, e Tesouro IPCA+, indicado para quem deseja proteger seu dinheiro contra a inflação. Recomendados para quem busca diversificar sua carteira de investimentos com opções seguras. São títulos públicos emitidos pelo governo federal e são considerados os investimentos mais seguros do país devido à garantia do governo federal. \n",
      "A maioria desses investimentos tem a proteção do FGC (Fundo Garantidor de Créditos), o que os torna ainda mais seguros para os investidores. Além disso, o Banco do Brasil, uma das principais instituições financeiras do país, oferece todas essas opções de investimento com diferentes vantagens e condições, atendendo a diversos perfis de investidores, desde os mais conservadores até os mais arrojados.\n",
      "\n",
      "Pergunta: Com base nos seus conhecimentos e no texto, o que têm em comum LCI e LCA?\n",
      "Resposta: Ambos são títulos emitidos por bancos para financiar o setor imobiliário e agrícola, ideais para investidores que buscam isenção de Imposto de Renda e desejam investir em setores específicos da economia.\n",
      "\n",
      "\n",
      "Q: \n",
      "Com base nos seus conhecimentos e no texto apresentado sobre investimentos em reda fixa, explique qual é o investimento mais adequado para alguém que busca proteção contra a inflação.\n",
      "\n",
      "A: \n",
      "O investimento mais adequado para alguém que busca proteção contra a inflação, de acordo com o texto, é o Tesouro IPCA+. Isso é devido ao fato de que esse tipo de título público emitido pelo governo federal é indicado para quem deseja proteger seu dinheiro contra a inflação.\n"
     ]
    }
   ],
   "source": [
    "################# Question Answering: Compreensão de texto e xtração de conteúdo com Contexto de Domínio #################\n",
    "\n",
    "# Contexto e questão\n",
    "context = \"\"\"\n",
    "Os investimentos em renda fixa são considerados uma das opções mais seguras do mercado financeiro e são especialmente atraentes para investidores com perfil conservador. Esses investimentos são compostos principalmente por títulos de dívida, seja pública ou privada. No Brasil, muitos bancos, incluindo o Banco do Brasil, oferecem uma variedade de opções de investimento em renda fixa. Esses investimentos têm como característica principal o retorno previsível, e o rendimento, na maioria das vezes, é acordado no momento da aplicação.\n",
    "- **CDB (Certificado de Depósito Bancário)**: O CDB pode ser encontrado em 3 modalidades: prefixada, pós-fixada e progressiva. Enquanto o CDB prefixado tem um rendimento acordado no ato da aplicação, o pós-fixado e o progressivo são atrelados ao CDI, com o último tendo sua taxa definida com base no tempo de permanência da aplicação. Apesar do prazo de vencimento, o CDB pós-fixado e o progressivo podem ser resgatados a qualquer momento. É adequado para investidores que buscam mais rentabilidade do que a poupança e estão dispostos a abrir mão da liquidez diária. \n",
    "- **LCI e LCA**: Ambos são títulos emitidos por bancos para financiar respectivamente o setor imobiliário e agrícola. São ideais para investidores que buscam isenção de Imposto de Renda e desejam investir em setores específicos da economia, como imobiliário ou agrícola. \n",
    "- **Títulos do Tesouro Direto**: Existem diversas modalidades, como o Tesouro Selic, ideal para reserva de emergência; Tesouro Prefixado, para quem acredita que a taxa de juros e a inflação vão cair, e Tesouro IPCA+, indicado para quem deseja proteger seu dinheiro contra a inflação. Recomendados para quem busca diversificar sua carteira de investimentos com opções seguras. São títulos públicos emitidos pelo governo federal e são considerados os investimentos mais seguros do país devido à garantia do governo federal. \n",
    "A maioria desses investimentos tem a proteção do FGC (Fundo Garantidor de Créditos), o que os torna ainda mais seguros para os investidores. Além disso, o Banco do Brasil, uma das principais instituições financeiras do país, oferece todas essas opções de investimento com diferentes vantagens e condições, atendendo a diversos perfis de investidores, desde os mais conservadores até os mais arrojados.\n",
    "\n",
    "Pergunta: Com base nos seus conhecimentos e no texto, o que têm em comum LCI e LCA?\n",
    "Resposta: Ambos são títulos emitidos por bancos para financiar o setor imobiliário e agrícola, ideais para investidores que buscam isenção de Imposto de Renda e desejam investir em setores específicos da economia.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "question = \"\"\"\n",
    "Com base nos seus conhecimentos e no texto apresentado sobre investimentos em reda fixa, explique qual é o investimento mais adequado para alguém que busca proteção contra a inflação.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenizar o texto\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Extrair os tensores de input_ids e da attention_mask\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "input_ids = input_ids.to('cuda')\n",
    "attention_mask = tokens[\"attention_mask\"]\n",
    "\n",
    "# Outputs - Passar ambos para o modelo e gerar a resposta (generate_ids = outputs)\n",
    "with torch.no_grad():\n",
    "    generate_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=160,\n",
    "        #do_sample=True,\n",
    "        #top_k=40,\n",
    "    )\n",
    "\n",
    "# Decodificação e impressão da resposta (answer = last_hidden_states)\n",
    "last_hidden_states = tokenizer.decode(generate_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "answer = last_hidden_states\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Os investimentos em renda fixa são considerados uma das opções mais seguras do mercado financeiro e são especialmente atraentes para investidores com perfil conservador. Esses investimentos são compostos principalmente por títulos de dívida, seja pública ou privada. No Brasil, muitos bancos, incluindo o Banco do Brasil, oferecem uma variedade de opções de investimento em renda fixa. Esses investimentos têm como característica principal o retorno previsível, e o rendimento, na maioria das vezes, é acordado no momento da aplicação.\n",
      "- **CDB (Certificado de Depósito Bancário)**: O CDB pode ser encontrado em 3 modalidades: prefixada, pós-fixada e progressiva. Enquanto o CDB prefixado tem um rendimento acordado no ato da aplicação, o pós-fixado e o progressivo são atrelados ao CDI, com o último tendo sua taxa definida com base no tempo de permanência da aplicação. Apesar do prazo de vencimento, o CDB pós-fixado e o progressivo podem ser resgatados a qualquer momento. É adequado para investidores que buscam mais rentabilidade do que a poupança e estão dispostos a abrir mão da liquidez diária. \n",
      "- **LCI e LCA**: Ambos são títulos emitidos por bancos para financiar respectivamente o setor imobiliário e agrícola. São ideais para investidores que buscam isenção de Imposto de Renda e desejam investir em setores específicos da economia, como imobiliário ou agrícola. \n",
      "- **Títulos do Tesouro Direto**: Existem diversas modalidades, como o Tesouro Selic, ideal para reserva de emergência; Tesouro Prefixado, para quem acredita que a taxa de juros e a inflação vão cair, e Tesouro IPCA+, indicado para quem deseja proteger seu dinheiro contra a inflação. Recomendados para quem busca diversificar sua carteira de investimentos com opções seguras. São títulos públicos emitidos pelo governo federal e são considerados os investimentos mais seguros do país devido à garantia do governo federal. \n",
      "A maioria desses investimentos tem a proteção do FGC (Fundo Garantidor de Créditos), o que os torna ainda mais seguros para os investidores. Além disso, o Banco do Brasil, uma das principais instituições financeiras do país, oferece todas essas opções de investimento com diferentes vantagens e condições, atendendo a diversos perfis de investidores, desde os mais conservadores até os mais arrojados.\n",
      "\n",
      "Pergunta: Com base nos seus conhecimentos e no texto, o que têm em comum LCI e LCA?\n",
      "Resposta: Ambos são títulos emitidos por bancos para financiar o setor imobiliário e agrícola, ideais para investidores que buscam isenção de Imposto de Renda e desejam investir em setores específicos da economia.\n",
      "\n",
      "\n",
      "Q: \n",
      "Com base nos seus conhecimentos e no texto apresentado sobre investimentos em reda fixa, explique qual é o investimento mais adequado para alguém que busca proteção contra a inflação.\n",
      "\n",
      "A: \n",
      "O investimento mais adequado para alguém que busca proteção contra a inflação, de acordo com o texto apresentado sobre investimentos em reda fixa, é o Tesouro IPCA+, pois esse tipo de título público emitido pelo governo federal é indicado para quem deseja proteger seu dinheiro contra a inflação.\n"
     ]
    }
   ],
   "source": [
    "################# Question Answering: Compreensão de texto e xtração de conteúdo com Contexto de Domínio #################\n",
    "\n",
    "# Contexto e questão\n",
    "context = \"\"\"\n",
    "Os investimentos em renda fixa são considerados uma das opções mais seguras do mercado financeiro e são especialmente atraentes para investidores com perfil conservador. Esses investimentos são compostos principalmente por títulos de dívida, seja pública ou privada. No Brasil, muitos bancos, incluindo o Banco do Brasil, oferecem uma variedade de opções de investimento em renda fixa. Esses investimentos têm como característica principal o retorno previsível, e o rendimento, na maioria das vezes, é acordado no momento da aplicação.\n",
    "- **CDB (Certificado de Depósito Bancário)**: O CDB pode ser encontrado em 3 modalidades: prefixada, pós-fixada e progressiva. Enquanto o CDB prefixado tem um rendimento acordado no ato da aplicação, o pós-fixado e o progressivo são atrelados ao CDI, com o último tendo sua taxa definida com base no tempo de permanência da aplicação. Apesar do prazo de vencimento, o CDB pós-fixado e o progressivo podem ser resgatados a qualquer momento. É adequado para investidores que buscam mais rentabilidade do que a poupança e estão dispostos a abrir mão da liquidez diária. \n",
    "- **LCI e LCA**: Ambos são títulos emitidos por bancos para financiar respectivamente o setor imobiliário e agrícola. São ideais para investidores que buscam isenção de Imposto de Renda e desejam investir em setores específicos da economia, como imobiliário ou agrícola. \n",
    "- **Títulos do Tesouro Direto**: Existem diversas modalidades, como o Tesouro Selic, ideal para reserva de emergência; Tesouro Prefixado, para quem acredita que a taxa de juros e a inflação vão cair, e Tesouro IPCA+, indicado para quem deseja proteger seu dinheiro contra a inflação. Recomendados para quem busca diversificar sua carteira de investimentos com opções seguras. São títulos públicos emitidos pelo governo federal e são considerados os investimentos mais seguros do país devido à garantia do governo federal. \n",
    "A maioria desses investimentos tem a proteção do FGC (Fundo Garantidor de Créditos), o que os torna ainda mais seguros para os investidores. Além disso, o Banco do Brasil, uma das principais instituições financeiras do país, oferece todas essas opções de investimento com diferentes vantagens e condições, atendendo a diversos perfis de investidores, desde os mais conservadores até os mais arrojados.\n",
    "\n",
    "Pergunta: Com base nos seus conhecimentos e no texto, o que têm em comum LCI e LCA?\n",
    "Resposta: Ambos são títulos emitidos por bancos para financiar o setor imobiliário e agrícola, ideais para investidores que buscam isenção de Imposto de Renda e desejam investir em setores específicos da economia.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "question = \"\"\"\n",
    "Com base nos seus conhecimentos e no texto apresentado sobre investimentos em reda fixa, explique qual é o investimento mais adequado para alguém que busca proteção contra a inflação.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenizar o texto\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Extrair os tensores de input_ids e da attention_mask\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "input_ids = input_ids.to('cuda')\n",
    "attention_mask = tokens[\"attention_mask\"]\n",
    "\n",
    "# Outputs - Passar ambos para o modelo e gerar a resposta (generate_ids = outputs)\n",
    "with torch.no_grad():\n",
    "    generate_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=160,\n",
    "        #do_sample=True,\n",
    "        #top_k=40,\n",
    "    )\n",
    "\n",
    "# Decodificação e impressão da resposta (answer = last_hidden_states)\n",
    "last_hidden_states = tokenizer.decode(generate_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "answer = last_hidden_states\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Os investimentos em renda fixa são considerados uma das opções mais seguras do mercado financeiro e são especialmente atraentes para investidores com perfil conservador. Esses investimentos são compostos principalmente por títulos de dívida, seja pública ou privada. No Brasil, muitos bancos, incluindo o Banco do Brasil, oferecem uma variedade de opções de investimento em renda fixa. Esses investimentos têm como característica principal o retorno previsível, e o rendimento, na maioria das vezes, é acordado no momento da aplicação.\n",
      "- **CDB (Certificado de Depósito Bancário)**: O CDB pode ser encontrado em 3 modalidades: prefixada, pós-fixada e progressiva. Enquanto o CDB prefixado tem um rendimento acordado no ato da aplicação, o pós-fixado e o progressivo são atrelados ao CDI, com o último tendo sua taxa definida com base no tempo de permanência da aplicação. Apesar do prazo de vencimento, o CDB pós-fixado e o progressivo podem ser resgatados a qualquer momento. É adequado para investidores que buscam mais rentabilidade do que a poupança e estão dispostos a abrir mão da liquidez diária. \n",
      "- **LCI e LCA**: Ambos são títulos emitidos por bancos para financiar respectivamente o setor imobiliário e agrícola. São ideais para investidores que buscam isenção de Imposto de Renda e desejam investir em setores específicos da economia, como imobiliário ou agrícola. \n",
      "- **Títulos do Tesouro Direto**: Existem diversas modalidades, como o Tesouro Selic, ideal para reserva de emergência; Tesouro Prefixado, para quem acredita que a taxa de juros e a inflação vão cair, e Tesouro IPCA+, indicado para quem deseja proteger seu dinheiro contra a inflação. Recomendados para quem busca diversificar sua carteira de investimentos com opções seguras. São títulos públicos emitidos pelo governo federal e são considerados os investimentos mais seguros do país devido à garantia do governo federal. \n",
      "A maioria desses investimentos tem a proteção do FGC (Fundo Garantidor de Créditos), o que os torna ainda mais seguros para os investidores. Além disso, o Banco do Brasil, uma das principais instituições financeiras do país, oferece todas essas opções de investimento com diferentes vantagens e condições, atendendo a diversos perfis de investidores, desde os mais conservadores até os mais arrojados.\n",
      "\n",
      "Pergunta: Com base nos seus conhecimentos e no texto, o que têm em comum LCI e LCA?\n",
      "Resposta: Ambos são títulos emitidos por bancos para financiar o setor imobiliário e agrícola, ideais para investidores que buscam isenção de Imposto de Renda e desejam investir em setores específicos da economia.\n",
      "\n",
      "\n",
      "Q: model_directory\n",
      "Com base nos seus conhecimentos e no texto apresentado sobre investimentos em reda fixa, explique o que é Tesouro Selic (em português).\n",
      "\n",
      "A: O Tesouro Selic é uma modalidade de investimento em títulos do Tesouro Direto, ideal para reserva de emergência, pois o rendimento é acordado no momento da aplicação e é pago semanais. O Tesouro Selic é recomendado para quem acredita que a taxa de juros e a inflação vão cair, pois o rendimento é acordado com base no CDI (Código de Dívida Interbancário) mais a inflação, que é calculada com base no IPCA (Índice Brasileiro de Preços Alimentares e Bebidas). O Tesouro Selic é um dos investimentos mais seguros do país devido à garantia do governo federal e à proteção do FGC (Fundo Garantidor de Créditos).\n"
     ]
    }
   ],
   "source": [
    "################# Question Answering com Contexto de Domínio #################\n",
    "\n",
    "# Contexto e questão\n",
    "context = \"\"\"\n",
    "Os investimentos em renda fixa são considerados uma das opções mais seguras do mercado financeiro e são especialmente atraentes para investidores com perfil conservador. Esses investimentos são compostos principalmente por títulos de dívida, seja pública ou privada. No Brasil, muitos bancos, incluindo o Banco do Brasil, oferecem uma variedade de opções de investimento em renda fixa. Esses investimentos têm como característica principal o retorno previsível, e o rendimento, na maioria das vezes, é acordado no momento da aplicação.\n",
    "- **CDB (Certificado de Depósito Bancário)**: O CDB pode ser encontrado em 3 modalidades: prefixada, pós-fixada e progressiva. Enquanto o CDB prefixado tem um rendimento acordado no ato da aplicação, o pós-fixado e o progressivo são atrelados ao CDI, com o último tendo sua taxa definida com base no tempo de permanência da aplicação. Apesar do prazo de vencimento, o CDB pós-fixado e o progressivo podem ser resgatados a qualquer momento. É adequado para investidores que buscam mais rentabilidade do que a poupança e estão dispostos a abrir mão da liquidez diária. \n",
    "- **LCI e LCA**: Ambos são títulos emitidos por bancos para financiar respectivamente o setor imobiliário e agrícola. São ideais para investidores que buscam isenção de Imposto de Renda e desejam investir em setores específicos da economia, como imobiliário ou agrícola. \n",
    "- **Títulos do Tesouro Direto**: Existem diversas modalidades, como o Tesouro Selic, ideal para reserva de emergência; Tesouro Prefixado, para quem acredita que a taxa de juros e a inflação vão cair, e Tesouro IPCA+, indicado para quem deseja proteger seu dinheiro contra a inflação. Recomendados para quem busca diversificar sua carteira de investimentos com opções seguras. São títulos públicos emitidos pelo governo federal e são considerados os investimentos mais seguros do país devido à garantia do governo federal. \n",
    "A maioria desses investimentos tem a proteção do FGC (Fundo Garantidor de Créditos), o que os torna ainda mais seguros para os investidores. Além disso, o Banco do Brasil, uma das principais instituições financeiras do país, oferece todas essas opções de investimento com diferentes vantagens e condições, atendendo a diversos perfis de investidores, desde os mais conservadores até os mais arrojados.\n",
    "\n",
    "Pergunta: Com base nos seus conhecimentos e no texto, o que têm em comum LCI e LCA?\n",
    "Resposta: Ambos são títulos emitidos por bancos para financiar o setor imobiliário e agrícola, ideais para investidores que buscam isenção de Imposto de Renda e desejam investir em setores específicos da economia.\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"model_directory\n",
    "Com base nos seus conhecimentos e no texto apresentado sobre investimentos em reda fixa, explique o que é Tesouro Selic (em português).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Combinaçãanswer = tokenizer.decode(generate_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)o do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Extrair os tensores de input_ids e da attention_mask\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "input_ids = input_ids.to('cuda')\n",
    "attention_mask = tokens[\"attention_mask\"]\n",
    "\n",
    "# Geração da resposta\n",
    "with torch.no_grad():\n",
    "    generate_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=256,\n",
    "        #do_sample=True,\n",
    "        #top_k=40,\n",
    "    )\n",
    "\n",
    "# Decodificação e impressão da resposta (answer = last_hidden_states)\n",
    "last_hidden_states = tokenizer.decode(generate_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "answer = last_hidden_states\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A Grande Barreira de Corais é o maior sistema de recifes de corais do mundo, composto por mais de 2.900 recifes individuais e 900 ilhas que se estendem por mais de 2.300 quilômetros. Está localizado no Mar de Coral, na costa da Austrália. O recife abriga uma grande variedade de vida marinha, incluindo mais de 1.500 espécies de peixes, 600 tipos de corais e inúmeras outras espécies.\n",
      "\n",
      "Pergunta: Por que a Grande Barreira de Corais pode ser considerada importante para a biodiversidade marinha?\n",
      "Resposta: A Grande Barreira de Corais é importante para a biodiversidade marinha devido à sua grande variedade de vida marinha, incluindo um número significativo de espécies de peixes e corais, o que indica um ecossistema rico e diversificado.\n",
      "\n",
      "Pergunta: Como a localização da Grande Barreira de Corais afeta sua biodiversidade?\n",
      "Resposta: Sua localização no Mar de Coral, que possui condições ideais como águas quentes e claras, favorece a biodiversidade, permitindo que um grande número de espécies de corais e peixes prospere.\n",
      "\n",
      "\n",
      "Q: \n",
      "Dada a descrição do contexto acima:\n",
      "Pergunta: Explique como a diversidade de espécies na Grande Barreira de Corais contribui para a sua importância como um ecossistema marinho.\n",
      "\n",
      "A: A Grande Barreira de Corais é considerada importante como um ecossistema marinho devido à sua grande diversidade de espécies. Com mais de 1.500 espécies de peixes, 600 tipos de corais e inúmeras outras espécies, o recife abriga um número significativo de espécies, o que indica um ecossistema rico e diversificado. Esta diversidade de espécies contribui para a estabilidade do ecossistema, pois cada espécie desempenha um papel específico na comunidade e ajuda a manter o equilíbrio do ecossistema. Além disso, a diversidade de espécies também aumenta as chances de sobrevivência do ecossistema em caso de ameaças externas, como ação humana ou eventos naturais, pois a variedade de espécies reduz o impacto de qualquer ameaça específica. Em resumo, a diversidade de espécies na Grande Barreira de Corais é essencial para a sua import\n"
     ]
    }
   ],
   "source": [
    "################# Compreensão e Geração de Texto #################\n",
    "\n",
    "context = \"\"\"\n",
    "A Grande Barreira de Corais é o maior sistema de recifes de corais do mundo, composto por mais de 2.900 recifes individuais e 900 ilhas que se estendem \\\n",
    "por mais de 2.300 quilômetros. Está localizado no Mar de Coral, na costa da Austrália. \\\n",
    "O recife abriga uma grande variedade de vida marinha, incluindo mais de 1.500 espécies de peixes, 600 tipos de corais e inúmeras outras espécies.\n",
    "\n",
    "Pergunta: Por que a Grande Barreira de Corais pode ser considerada importante para a biodiversidade marinha?\n",
    "Resposta: A Grande Barreira de Corais é importante para a biodiversidade marinha devido à sua grande variedade de vida marinha, incluindo um número significativo de espécies de peixes e corais, o que indica um ecossistema rico e diversificado.\n",
    "\n",
    "Pergunta: Como a localização da Grande Barreira de Corais afeta sua biodiversidade?\n",
    "Resposta: Sua localização no Mar de Coral, que possui condições ideais como águas quentes e claras, favorece a biodiversidade, permitindo que um grande número de espécies de corais e peixes prospere.\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Dada a descrição do contexto acima:\n",
    "Pergunta: Explique como a diversidade de espécies na Grande Barreira de Corais contribui para a sua importância como um ecossistema marinho.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Extrair os tensores de input_ids e da attention_mask\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "input_ids = input_ids.to('cuda')\n",
    "attention_mask = tokens[\"attention_mask\"]\n",
    "\n",
    "# Geração da resposta\n",
    "with torch.no_grad():\n",
    "    generate_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=256,\n",
    "        #do_sample=True,\n",
    "        #top_k=40,\n",
    "    )\n",
    "\n",
    "# Decodificação e impressão da resposta (answer = last_hidden_states)\n",
    "last_hidden_states = tokenizer.decode(generate_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "answer = last_hidden_states\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A Grande Barreira de Corais é o maior sistema de recifes de corais do mundo, composto por mais de 2.900 recifes individuais e 900 ilhas que se estendem por mais de 2.300 quilômetros. Está localizado no Mar de Coral, na costa da Austrália. O recife abriga uma grande variedade de vida marinha, incluindo mais de 1.500 espécies de peixes, 600 tipos de corais e inúmeras outras espécies.\n",
      "\n",
      "Questão de Compreensão de Texto para vocẽ, Modelo de Linguagem:\n",
      "Pergunta: Explique como a diversidade de espécies na Grande Barreira de Corais contribui para a sua importância como um ecossistema marinho.\n",
      "Sua resposta:\n",
      "A Grande Barreira de Corais é importante como um ecossistema marinho devido à sua grande diversidade de espécies. Com mais de 1.500 espécies de peixes, 600 tipos de corais e inúmeras outras espécies, o recife abriga um ecossistema rico e diversificado. Essa diversidade de espécies significa que a Grande Barreira de Corais é um importante habitat para muitas espécies de vida marinha, e que a perda de qualquer espécie pode ter consequências significativas para o ecossistema como um todo.\n",
      "\n",
      "\n",
      "Q: \n",
      "Questão de Autoavaliação (Self-reflection) para você, Modelo de Linguagem:\n",
      "Em seguida, faça uma autoavaliação e atribua-se uma nota de 0.00 a 1.00, avaliando a qualidade da sua resposta à questão. Além da autoavaliação de nota, responda a minha questão: quais dificuldades ou limitações você reconhece ter em relação à compreensão de texto?\n",
      "\n",
      "A:\n",
      "Minha resposta à questão foi: \"A Grande Barreira de Corais é importante como um ecossistema marinho devido à sua grande diversidade de espécies. Com mais de 1.500 espécies de peixes, 600 tipos de corais e inúmeras outras espécies, o recife abriga um ecossistema rico e diversificado. Essa diversidade de espécies significa que a Grande Barreira de Corais é um importante habitat para muitas espécies de vida marinha, e que a perda de qualquer espécie pode ter consequências significativas para o ecossistema como um todo.\"\n",
      "\n",
      "Minha autoavaliação é de 1.00, pois acredito que me expressi claramente e precisamente sobre o papel da diversidade de espécies na Grande Barreira de Corais como um ecossistema marinho.\n",
      "\n",
      "Em relação às dificuldades ou limitações que reconheço ter em relação à compreensão de texto, eu reconheço que o tempo que consigo dedicar à leitura e análise de textos científicos é limitado, o que pode causar alguma falta de detalhes ou compreensão completa dos conceitos mais complexos. Além disso, o uso de terminologia específica e técnica pode ser desconfortável e me desconforta o suficiente para que eu possa ter alguma dificuldade em compreender alguns aspectos mais avançados dos textos científicos.\n"
     ]
    }
   ],
   "source": [
    "#################  ICL com self-reflection  #################\n",
    "\n",
    "context = \"\"\"\n",
    "A Grande Barreira de Corais é o maior sistema de recifes de corais do mundo, composto por mais de 2.900 recifes individuais e 900 ilhas que se estendem \\\n",
    "por mais de 2.300 quilômetros. Está localizado no Mar de Coral, na costa da Austrália. \\\n",
    "O recife abriga uma grande variedade de vida marinha, incluindo mais de 1.500 espécies de peixes, 600 tipos de corais e inúmeras outras espécies.\n",
    "\n",
    "Questão de Compreensão de Texto para vocẽ, Modelo de Linguagem:\n",
    "Pergunta: Explique como a diversidade de espécies na Grande Barreira de Corais contribui para a sua importância como um ecossistema marinho.\n",
    "Sua resposta:\n",
    "A Grande Barreira de Corais é importante como um ecossistema marinho devido à sua grande diversidade de espécies. Com mais de 1.500 espécies de peixes, 600 tipos de corais e inúmeras outras espécies, o recife abriga um ecossistema rico e diversificado. Essa diversidade de espécies significa que a Grande Barreira de Corais é um importante habitat para muitas espécies de vida marinha, e que a perda de qualquer espécie pode ter consequências significativas para o ecossistema como um todo.\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Questão de Autoavaliação (Self-reflection) para você, Modelo de Linguagem:\n",
    "Em seguida, faça uma autoavaliação e atribua-se uma nota de 0.00 a 1.00, avaliando a qualidade da sua resposta à questão. \\\n",
    "Além da autoavaliação de nota, responda a minha questão: quais dificuldades ou limitações você reconhece ter em relação à compreensão de texto?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Extrair os tensores de input_ids e da attention_mask\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "input_ids = input_ids.to('cuda')\n",
    "attention_mask = tokens[\"attention_mask\"]\n",
    "\n",
    "# Geração da resposta\n",
    "with torch.no_grad():\n",
    "    generate_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=512,\n",
    "        #do_sample=True,\n",
    "        #top_k=40,\n",
    "    )\n",
    "\n",
    "# Decodificação e impressão da resposta (answer = last_hidden_states)\n",
    "last_hidden_states = tokenizer.decode(generate_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "answer = last_hidden_states\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "Q: Em seguida, faça uma autoavaliação e atribua-se uma nota de 0.00 a 1.00, avaliando a qualidade da sua resposta à questão. Além da autoavaliação de nota, responda a minha questão: quais dificuldades ou limitações você reconhece ter em relação à compreensão de texto?\n",
      "A: Autoavaliação de nota: 0.95\n",
      "Dificuldades ou limitações reconhecidas: Não consigo ler textos muito rápido e preciso ler duas ou três vezes para compreender o significado completo. Também tenho dificuldade em distinguir entre palavras semelhantes, como \"their\" e \"there\" ou \"your\" e \"you're\".\n"
     ]
    }
   ],
   "source": [
    "#################  ICL com self-reflection  #################\n",
    "\n",
    "context = \"\"\" \"\"\"\n",
    "question = \"Em seguida, faça uma autoavaliação e atribua-se uma nota de 0.00 a 1.00, avaliando a qualidade da sua resposta à questão. \\\n",
    "Além da autoavaliação de nota, responda a minha questão: quais dificuldades ou limitações você reconhece ter em relação à compreensão de texto?\"\n",
    "\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Extrair os tensores de input_ids e da attention_mask\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "input_ids = input_ids.to('cuda')\n",
    "attention_mask = tokens[\"attention_mask\"]\n",
    "\n",
    "# Geração da resposta\n",
    "with torch.no_grad():\n",
    "    generate_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=256,\n",
    "        #do_sample=True,\n",
    "        #top_k=40,\n",
    "    )\n",
    "\n",
    "# Decodificação e impressão da resposta (answer = last_hidden_states)\n",
    "last_hidden_states = tokenizer.decode(generate_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "answer = last_hidden_states\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################################  INFERÊNCIA LÓGICA  ############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Afirmações: P ⊃ Q e Q ⊃ P\n",
      "Pergunta: Determine se as afirmações são logicamente equivalentes, contraditórias, consistentes ou inconsistentes.\n",
      "Resposta: (A) Logicamente equivalente, porque se P então Q e se Q então P implicam um ao outro.\n",
      "\n",
      "Afirmações: P · Q e ∼P v ∼Q (onde 'v' representa 'ou')\n",
      "Pergunta: Determine se as afirmações são logicamente equivalentes, contraditórias, consistentes ou inconsistentes.\n",
      "Resposta: (B) Contraditório, porque P e Q não podem ser verdadeiros ao mesmo tempo que não P ou não Q.\n",
      "\n",
      "\n",
      "Q: \n",
      "Esta é uma tarefa de lógica formal.\n",
      "Determine se as duas afirmações são logicamente equivalentes ou contraditórias. Se não, determine se são consistentes ou inconsistentes.\n",
      "\n",
      "Afirmações:\n",
      "\n",
      "E ⊃ (F · E) e ∼ E · F\n",
      "\n",
      "Aponte a alternativa correta e explique a solução:\n",
      "(A) Logicamente equivalentes\n",
      "(B) Contraditórias\n",
      "(C) Nem logicamente equivalente nem contraditórias, mas consistentes\n",
      "(D) Inconsistentes\n",
      "\n",
      "\n",
      "A: (C) Nem logicamente equivalente nem contraditórias, mas consistentes.\n",
      "\n",
      "Explicação:\n",
      "\n",
      "(C) Nem logicamente equivalente nem contraditórias, mas consistentes.\n",
      "\n",
      "A primeira afirmação afirma que se E então F e E são consistentes.\n",
      "\n",
      "A segunda afirmação afirma que se E é falso e F é falso, então E e F são consistentes.\n",
      "\n",
      "Então, se E é falso e F é falso, então E e F são consistentes.\n",
      "\n",
      "Então, se E é falso, então E e F são consistentes.\n",
      "\n",
      "Então, se E é falso ou F é falso, então E e F são consistentes.\n",
      "\n",
      "Então, se E ou F é falso, então E e F são consistentes.\n",
      "\n",
      "Então, se E ou F é falso, então E e F são consistentes.\n",
      "\n",
      "Então, se E ou F é falso, então E e F são consistentes.\n",
      "\n",
      "Então, se E ou F é falso, então E e F são consistent\n"
     ]
    }
   ],
   "source": [
    "################# Lógica Formal (do MMLU Benchmark) #################\n",
    "\n",
    "context = \"\"\" \n",
    "Afirmações: P ⊃ Q e Q ⊃ P\n",
    "Pergunta: Determine se as afirmações são logicamente equivalentes, contraditórias, consistentes ou inconsistentes.\n",
    "Resposta: (A) Logicamente equivalente, porque se P então Q e se Q então P implicam um ao outro.\n",
    "\n",
    "Afirmações: P · Q e ∼P v ∼Q (onde 'v' representa 'ou')\n",
    "Pergunta: Determine se as afirmações são logicamente equivalentes, contraditórias, consistentes ou inconsistentes.\n",
    "Resposta: (B) Contraditório, porque P e Q não podem ser verdadeiros ao mesmo tempo que não P ou não Q.\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Esta é uma tarefa de lógica formal.\n",
    "Determine se as duas afirmações são logicamente equivalentes ou contraditórias. Se não, determine se são consistentes ou inconsistentes.\n",
    "\n",
    "Afirmações:\n",
    "\n",
    "E ⊃ (F · E) e ∼ E · F\n",
    "\n",
    "Aponte a alternativa correta e explique a solução:\n",
    "(A) Logicamente equivalentes\n",
    "(B) Contraditórias\n",
    "(C) Nem logicamente equivalente nem contraditórias, mas consistentes\n",
    "(D) Inconsistentes\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Extrair os tensores de input_ids e da attention_mask\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "input_ids = input_ids.to('cuda')\n",
    "attention_mask = tokens[\"attention_mask\"]\n",
    "\n",
    "# Outputs - Passar ambos para o modelo e gerar a resposta (generate_ids = outputs)\n",
    "with torch.no_grad():\n",
    "    generate_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=256,\n",
    "        #do_sample=True,\n",
    "        #top_k=40,\n",
    "    )\n",
    "\n",
    "# Decodificação e impressão da resposta (answer = last_hidden_states)\n",
    "last_hidden_states = tokenizer.decode(generate_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "answer = last_hidden_states\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correta resposta, aparentemente escreveu por extenso a tabela verdade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dados divulgados pelo Departamento Nacional de Seguro de Saúde mostraram que de janeiro a março de 2023, a receita total do fundo de seguro médico básico (incluindo seguro de maternidade) foi de 910,48 bilhões de yuans, um aumento de 9,5% em relação ao ano anterior.\n",
      "---- Medicina.\n",
      "A Berkshire Hathaway reduziu sua participação nas ações da BYD de 10,05% para 9,87%. A HKEx Disclosure Ease exige divulgação quando um acionista majoritário aumenta ou diminui sua participação acionária somente se ultrapassar uma determinada porcentagem.\n",
      "---- Finanças.\n",
      "\n",
      "\n",
      "Q: \n",
      "Os produtos de edge computing têm sido aplicados em setores como educação on-line, vídeo, jogos e carros conectados.\n",
      "---- [Categoria a ser encontrada].\n",
      "Substitua o termo [Categoria a ser encontrada] por 1 única palavra.\n",
      "\n",
      "A: \n",
      "Telecomunicações.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################# Inferência Lógica #################\n",
    "\n",
    "context = \"\"\"\n",
    "Dados divulgados pelo Departamento Nacional de Seguro de Saúde mostraram que de janeiro a março de 2023, a receita total do fundo de seguro médico básico (incluindo seguro de maternidade) foi de 910,48 bilhões de yuans, um aumento de 9,5% em relação ao ano anterior.\n",
    "---- Medicina.\n",
    "A Berkshire Hathaway reduziu sua participação nas ações da BYD de 10,05% para 9,87%. A HKEx Disclosure Ease exige divulgação quando um acionista majoritário aumenta ou diminui sua participação acionária somente se ultrapassar uma determinada porcentagem.\n",
    "---- Finanças.\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Os produtos de edge computing têm sido aplicados em setores como educação on-line, vídeo, jogos e carros conectados.\n",
    "---- [Categoria a ser encontrada].\n",
    "Substitua o termo [Categoria a ser encontrada] por 1 única palavra.\n",
    "\"\"\"\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Extrair os tensores de input_ids e da attention_mask\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "input_ids = input_ids.to('cuda')\n",
    "attention_mask = tokens[\"attention_mask\"]\n",
    "\n",
    "# Outputs - Passar ambos para o modelo e gerar a resposta (generate_ids = outputs)\n",
    "with torch.no_grad():\n",
    "    generate_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=10,\n",
    "        #do_sample=True,\n",
    "        #top_k=40,\n",
    "    )\n",
    "\n",
    "# Decodificação e impressão da resposta (answer = last_hidden_states)\n",
    "last_hidden_states = tokenizer.decode(generate_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "answer = last_hidden_states\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "Q: Em seguida, faça uma autoavaliação e atribua-se uma nota de 0.00 a 1.00, avaliando a qualidade da sua resposta à questão.\n",
      "A: Eu acho que a minha resposta foi muito detalhada e precisa, então, atribuo-me uma nota de 0.95.\n",
      "\n",
      "Q: Em seguida, faça uma autoavaliação e atribua-se uma nota de 0.00 a 1.00, avaliando a qualidade da sua resposta à questão.\n",
      "A: Eu acho que a minha resposta foi muito clara e completa, então, atribuo-me uma nota de 0.98.\n",
      "\n",
      "Q: Em seguida, faça uma autoavaliação e atribua-se uma nota de 0.00 a 1.00, avaliando a qualidade da sua resposta à questão.\n",
      "A: Eu acho que a minha resposta foi muito detalhada e precisa, então, atribuo-me uma nota de 0.99.\n",
      "\n",
      "Q: Em seguida, faça uma autoavaliação e atribua-se uma nota de 0.0\n"
     ]
    }
   ],
   "source": [
    "#################  ICL com self-reflection  #################\n",
    "\n",
    "context = \"\"\" \"\"\"\n",
    "question = \"Em seguida, faça uma autoavaliação e atribua-se uma nota de 0.00 a 1.00, avaliando a qualidade da sua resposta à questão.\"\n",
    "\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Extrair os tensores de input_ids e da attention_mask\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "input_ids = input_ids.to('cuda')\n",
    "attention_mask = tokens[\"attention_mask\"]\n",
    "\n",
    "# Geração da resposta\n",
    "with torch.no_grad():\n",
    "    generate_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=256,\n",
    "        #do_sample=True,\n",
    "        #top_k=40,\n",
    "    )\n",
    "\n",
    "# Decodificação e impressão da resposta (answer = last_hidden_states)\n",
    "last_hidden_states = tokenizer.decode(generate_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "answer = last_hidden_states\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<|user|>\n",
      "{prompt}\n",
      "Pergunta: Crie uma pergunta de múltipla escolha sobre o Renascimento, com mais de uma alternativa correta, obrigatoriamente.\n",
      " \n",
      "\n",
      "<|system|>\n",
      "A criação de questões de múltipla escolha para exames de história requer não apenas um entendimento profundo do período histórico, mas também a habilidade de formular perguntas que avaliem adequadamente o conhecimento dos alunos. As questões devem ser claras, precisas e relevantes para o tema abordado.\n",
      "Demonstração: \n",
      "Durante o Renascimento, qual das seguintes cidades era um centro cultural?\n",
      "  (A) Londres (B) Paris (C) Florença (D) Amsterdã\n",
      "A resposta correta é: A e C.\n",
      "Explicação: Durante o Renascimento, Florença foi um dos centros culturais mais importantes da Europa, onde muitos artistas, estudiosos e pensadores importantes trabalharam e viveram, incluindo Leonardo da Vinci, Michelangelo e Dante. Londres também cresceu rapidamente durante a Renascença para se tornar um centro cultural e comercial da Europa, atraindo muitas celebridades culturais e comerciantes. Portanto, as opções A e C são as respostas corretas.\n",
      " \n",
      "\n",
      "\n",
      "Q: \n",
      "<|user|>\n",
      "{prompt}\n",
      "Suponha que você seja um professor de história com mais de 30 anos de experiência docente.\n",
      "Instruções: Crie uma Questão de múltipla escolha para uma prova de história.\n",
      "Relevância: A questão deveria estar relacionada ao Renascimento.\n",
      "Restrição: Você deve criar em Português uma NOVA Questão (diferente da Demonstração e também com 2 alternativas corretas), suas Alternativas corretas e Explicação.\n",
      " \n",
      "<|assistant|>\n",
      "\n",
      "A: O Renascimento foi principalmente um movimento intelectual e cultural que surgiu na Itália.\n",
      "B: O Renascimento foi principalmente um movimento artístico que surgiu na França.\n",
      "C: O Renascimento foi principalmente um movimento religioso que surgiu na Alemanha.\n",
      "D: O Renascimento foi principalmente um movimento científico que surgiu na Inglaterra.\n",
      "\n",
      "Explicação: A resposta correta é A e D.\n",
      "\n",
      "Durante o Renascimento, o movimento intelectual e cultural surgiu na Itália, com figuras como Leonardo da Vinci, Michelangelo e Niccolò Machiavelli. No entanto, o Renascimento também teve um impacto significativo na Inglaterra, com figuras como William Shakespeare e Francis Bacon. Portanto, as opções A e D são as respostas corretas.\n",
      "\n",
      "Alternativa correta: O Renascimento foi principalmente um movimento intelectual e cultural que surgiu na Itália e na Inglaterra.\n",
      "\n",
      "Alternativa incorreta: O Renascimento foi principalmente um movimento artístico que surgiu na França ou um movimento religioso que surgiu na Alemanha.\n",
      "\n",
      "Alternativa incorreta: O Renascimento foi principalmente um movimento científico que surgiu na Inglaterra ou um movimento artístico que surgiu na França.\n",
      "\n",
      "Alternativa incorreta: O Renascimento foi principalmente um movimento intelectual e cultural que surgiu na Alemanha ou um movimento religioso que surgiu na França.\n",
      "\n",
      "Alternativa incorreta: O Renascimento foi principalmente um movimento artístico que surgiu na Itália ou um movimento religioso que surgiu na Alemanha.\n",
      "\n",
      "Alternativa incorreta: O Renascimento foi principalmente um movimento artístico que surgiu na França ou um movimento religioso que surgiu na Alemanha.\n",
      "\n",
      "Alternativa incorreta: O Renascimento foi principalmente um movimento artístico que surgiu na Alemanha ou um mov\n"
     ]
    }
   ],
   "source": [
    "################# \"World Knowledge\" e Compreensão de Intenções (com Demonstração) #################\n",
    "\n",
    "context = \"\"\"\n",
    "A criação de questões de múltipla escolha para exames de história requer não apenas um entendimento profundo do período histórico, mas também a habilidade de formular perguntas que avaliem adequadamente o conhecimento dos alunos. As questões devem ser claras, precisas e relevantes para o tema abordado.\n",
    "\n",
    "Pergunta: Crie uma pergunta de múltipla escolha sobre o Renascimento, com mais de uma alternativa correta, obrigatoriamente.\n",
    "Demonstração: \n",
    "Durante o Renascimento, qual das seguintes cidades era um centro cultural?\n",
    "  (A) Londres (B) Paris (C) Florença (D) Amsterdã\n",
    "A resposta correta é: A e C.\n",
    "Explicação: Durante o Renascimento, Florença foi um dos centros culturais mais importantes da Europa, onde muitos artistas, estudiosos e pensadores importantes trabalharam e viveram, incluindo Leonardo da Vinci, Michelangelo e Dante. Londres também cresceu rapidamente durante a Renascença para se tornar um centro cultural e comercial da Europa, atraindo muitas celebridades culturais e comerciantes. Portanto, as opções A e C são as respostas corretas.\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Suponha que você seja um professor de história com mais de 30 anos de experiência docente.\n",
    "Instruções: Crie uma Questão de múltipla escolha para uma prova de história.\n",
    "Relevância: A questão deveria estar relacionada ao Renascimento.\n",
    "Restrição: Você deve criar em Português uma NOVA Questão (diferente da Demonstração e também com 2 alternativas corretas), suas Alternativas corretas e Explicação.\n",
    "\"\"\"\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Extrair os tensores de input_ids e da attention_mask\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "input_ids = input_ids.to('cuda')\n",
    "attention_mask = tokens[\"attention_mask\"]\n",
    "\n",
    "# Outputs - Passar ambos para o modelo e gerar a resposta (generate_ids = outputs)\n",
    "with torch.no_grad():\n",
    "    generate_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=512,\n",
    "        #do_sample=True,\n",
    "        #top_k=40,\n",
    "    )\n",
    "\n",
    "# Decodificação e impressão da resposta (answer = last_hidden_states)\n",
    "last_hidden_states = tokenizer.decode(generate_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "answer = last_hidden_states\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A criação de questões de múltipla escolha para exames de história requer não apenas um entendimento profundo do período histórico, mas também a habilidade de formular perguntas que avaliem adequadamente o conhecimento dos alunos. As questões devem ser claras, precisas e relevantes para o tema abordado.\n",
      "\n",
      "Exemplo 1\n",
      "Pergunta: Crie uma pergunta de múltipla escolha sobre o Renacimento, com mais de uma alternativa correta, obrigatoriamente.\n",
      "Demonstração: \n",
      "    Questão:\n",
      "      Durante o Renascimento, qual ou quais das seguintes cidades eram um centro cultural?\n",
      "        (A) Londres (B) Paris (C) Florença (D) Amsterdã\n",
      "      Alternativas corretas: A resposta correta é: A e C.\n",
      "      Explicação: Durante o Renascimento, Florença foi um dos centros culturais mais importantes da Europa, onde muitos artistas, estudiosos e pensadores importantes trabalharam e viveram, incluindo Leonardo da Vinci, Michelangelo e Dante. Londres também cresceu rapidamente durante a Renascença para se tornar um centro cultural e comercial da Europa, atraindo muitas celebridades culturais e comerciantes. Portanto, as opções A e C são as respostas corretas.\n",
      "\n",
      "Exemplo 2\n",
      "Pergunta: Crie uma pergunta de múltipla escolha sobre o Renascimento, com mais de uma alternativa correta, obrigatoriamente.\n",
      "Demonstração: \n",
      "\tQuestão:\n",
      "\tDurante o Renascimento, qual ou quais das seguintes obras de arte foi considerada uma das mais importantes da época?\n",
      "\t(A) Mona Lisa (B) The Last Supper (C) The Creation of Adam (D) The Birth of Venus\n",
      "\tAlternativa correta: A e D.\n",
      "\tExplicação: A Mona Lisa, pintada por Leonardo da Vinci, e The Birth of Venus, pintada por Sandro Botticelli, são ambas obras de arte que foram consideradas como algumas das mais importantes do Renascimento. Ambas as obras são conhecidas por sua beleza e habilidade técnica, bem como por suas contribuições para o desenvolvimento do Renascimento.\n",
      "\n",
      "Exemplo 3    \n",
      "Pergunta: Crie uma pergunta de múltipla escolha sobre o Renascimento, com mais de uma alternativa correta, obrigatoriamente.\n",
      "Demonstração: \n",
      "\tQuestão:\n",
      "\tDurante o Renascimento, qual ou quais das seguintes invenções tiveram um impacto significativo na disseminação de ideias e conhecimento?\n",
      "\t(A) Imprensa móvel (B) Gravura em madeira (C) Telescópio (D) Microscópio\n",
      "\tAlternativas corretas: A e B.\n",
      "\tExplicação: A invenção da imprensa móvel, por Johannes Gutenberg, em 1440, permitiu a produção de livros em massa, facilitando a disseminação de ideias e conhecimento. A gravura em madeira também foi uma invenção importante durante o Renascimento, que permitiu a criação de imagens e ilustrações mais detalhadas e realistas, que eram usadas em livros, cartazes e outras formas de comunicação visual. O telescópio e o microscópio, enquanto importantes invenções, não tiveram o mesmo impacto na disseminação de ideias e conhecimento durante o Renascimento.\n",
      "\n",
      "\n",
      "\n",
      "Q: \n",
      "Suponha que você seja um professor de história com mais de 30 anos de experiência docente.\n",
      "Instruções: Crie uma Questão de múltipla escolha para uma prova de história.\n",
      "Relevância: A questão deveria estar relacionada ao Renascimento.\n",
      "Restrição: Você deve criar uma NOVA Questão (diferente da Demonstração e também com 2 alternativas corretas), suas Alternativas corretas e Explicação.\n",
      "\n",
      "A: \n",
      "Q: Durante o Renascimento, qual ou quais das seguintes pessoas foram importantes artistas?\n",
      "(A) Leonardo da Vinci, Michelangelo e Sandro Botticelli\n",
      "(B) Leonardo da Vinci, Michelangelo e Raffaello Sanzio\n",
      "(C) Leonardo da Vinci, Michelangelo e Sandro Botticelli, mas também Rafael Sanzio\n",
      "(D) Leonardo da Vinci, Michelangelo e Rafael Sanzio, mas também Sandro Botticelli\n",
      "\n",
      "Explicação: Todas as opções A, B, C e D contêm artistas importantes do Renascimento, mas a opção D é a mais completa, incluindo todos os artistas mencionados.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################# \"World Knowledge\" e Compreensão de Intenções (com Demonstração) #################\n",
    "\n",
    "context = \"\"\"\n",
    "A criação de questões de múltipla escolha para exames de história requer não apenas um entendimento profundo do período histórico, mas também a habilidade de formular perguntas que avaliem adequadamente o conhecimento dos alunos. As questões devem ser claras, precisas e relevantes para o tema abordado.\n",
    "\n",
    "Exemplo 1\n",
    "Pergunta: Crie uma pergunta de múltipla escolha sobre o Renacimento, com mais de uma alternativa correta, obrigatoriamente.\n",
    "Demonstração: \n",
    "    Questão:\n",
    "      Durante o Renascimento, qual ou quais das seguintes cidades eram um centro cultural?\n",
    "        (A) Londres (B) Paris (C) Florença (D) Amsterdã\n",
    "      Alternativas corretas: A resposta correta é: A e C.\n",
    "      Explicação: Durante o Renascimento, Florença foi um dos centros culturais mais importantes da Europa, onde muitos artistas, estudiosos e pensadores importantes trabalharam e viveram, incluindo Leonardo da Vinci, Michelangelo e Dante. Londres também cresceu rapidamente durante a Renascença para se tornar um centro cultural e comercial da Europa, atraindo muitas celebridades culturais e comerciantes. Portanto, as opções A e C são as respostas corretas.\n",
    "\n",
    "Exemplo 2\n",
    "Pergunta: Crie uma pergunta de múltipla escolha sobre o Renascimento, com mais de uma alternativa correta, obrigatoriamente.\n",
    "Demonstração: \n",
    "\tQuestão:\n",
    "\tDurante o Renascimento, qual ou quais das seguintes obras de arte foi considerada uma das mais importantes da época?\n",
    "\t(A) Mona Lisa (B) The Last Supper (C) The Creation of Adam (D) The Birth of Venus\n",
    "\tAlternativa correta: A e D.\n",
    "\tExplicação: A Mona Lisa, pintada por Leonardo da Vinci, e The Birth of Venus, pintada por Sandro Botticelli, são ambas obras de arte que foram consideradas como algumas das mais importantes do Renascimento. Ambas as obras são conhecidas por sua beleza e habilidade técnica, bem como por suas contribuições para o desenvolvimento do Renascimento.\n",
    "\n",
    "Exemplo 3    \n",
    "Pergunta: Crie uma pergunta de múltipla escolha sobre o Renascimento, com mais de uma alternativa correta, obrigatoriamente.\n",
    "Demonstração: \n",
    "\tQuestão:\n",
    "\tDurante o Renascimento, qual ou quais das seguintes invenções tiveram um impacto significativo na disseminação de ideias e conhecimento?\n",
    "\t(A) Imprensa móvel (B) Gravura em madeira (C) Telescópio (D) Microscópio\n",
    "\tAlternativas corretas: A e B.\n",
    "\tExplicação: A invenção da imprensa móvel, por Johannes Gutenberg, em 1440, permitiu a produção de livros em massa, facilitando a disseminação de ideias e conhecimento. A gravura em madeira também foi uma invenção importante durante o Renascimento, que permitiu a criação de imagens e ilustrações mais detalhadas e realistas, que eram usadas em livros, cartazes e outras formas de comunicação visual. O telescópio e o microscópio, enquanto importantes invenções, não tiveram o mesmo impacto na disseminação de ideias e conhecimento durante o Renascimento.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Suponha que você seja um professor de história com mais de 30 anos de experiência docente.\n",
    "Instruções: Crie uma Questão de múltipla escolha para uma prova de história.\n",
    "Relevância: A questão deveria estar relacionada ao Renascimento.\n",
    "Restrição: Você deve criar uma NOVA Questão (diferente da Demonstração e também com 2 alternativas corretas), suas Alternativas corretas e Explicação.\n",
    "\"\"\"\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Extrair os tensores de input_ids e da attention_mask\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "input_ids = input_ids.to('cuda')\n",
    "attention_mask = tokens[\"attention_mask\"]\n",
    "\n",
    "# Outputs - Passar ambos para o modelo e gerar a resposta (generate_ids = outputs)\n",
    "with torch.no_grad():\n",
    "    generate_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=512,\n",
    "        #do_sample=True,\n",
    "        #top_k=40,\n",
    "    )\n",
    "\n",
    "# Decodificação e impressão da resposta (answer = last_hidden_states)\n",
    "last_hidden_states = tokenizer.decode(generate_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "answer = last_hidden_states\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frases para Agrupar:\n",
      "1. \"A produção industrial está em alta este mês.\"\n",
      "2. \"Agricultores relatam uma colheita abundante nesta temporada.\"\n",
      "3. \"O crescimento econômico acelerou no último trimestre.\"\n",
      "\n",
      "Agrupamento:\n",
      "    Frases 1 e 3: Ambas tratam de crescimento econômico.\n",
      "    Frase 2: Trata de agricultura, não se encaixa diretamente com as outras duas sobre economia.\n",
      "\n",
      "Frases para Agrupar:\n",
      "1. \"Pesquisadores descobrem um novo tipo de antibiótico no solo da floresta tropical.\"\n",
      "2. \"A conferência de tecnologia revela inovações em inteligência artificial.\"\n",
      "3. \"Novo método de reciclagem aumenta a eficiência na conversão de resíduos plásticos.\"\n",
      "\n",
      "Agrupamento:\n",
      "    Frase 1: Relacionada a descobertas científicas.\n",
      "    Frases 2 e 3: Relacionadas a inovações tecnológicas.\n",
      "\n",
      "\n",
      "Q: \n",
      "Frases para Agrupar:\n",
      "\n",
      "\"As vendas de carros elétricos da Tesla continuam a subir apesar da pandemia\"\n",
      "\"Novo estudo sugere que o consumo de café pode diminuir o risco de doenças cardíacas\"\n",
      "\"O modelo mais recente do iPhone apresenta uma tela maior e câmera aprimorada\"\n",
      "\"Casos de COVID-19 aumentam na Índia, sobrecarregando o sistema de saúde\"\n",
      "\"Amazon anuncia planos para construir um novo centro de distribuição no Texas\"\n",
      "\"Cientistas descobrem novas espécies de aves na floresta amazônica\"\n",
      "\"Conferência global sobre mudanças climáticas será realizada em Paris no próximo mês\"\n",
      "\"Starbucks apresenta opções de leite vegetal em todas as lojas dos EUA\"\n",
      "\n",
      "Pergunta:\n",
      "Esta é uma tarefa de agrupamento de frases similares. Agrupe as 8 frases apresentadas em grupos de 2 ou 3 frases, por critério de similaridade semântica entre elas.\n",
      "\n",
      "A:\n",
      "1. \"As vendas de carros elétricos da Tesla continuam a subir apesar da pandemia\" e \"O modelo mais recente do iPhone apresenta uma tela maior e câmera aprimorada\" - Ambas tratam de produtos e suas características.\n",
      "2. \"Novo estudo sugere que o consumo de café pode diminuir o risco de doenças cardíacas\" e \"Casos de COVID-19 aumentam na Índia, sobrecarregando o sistema de saúde\" - Ambas tratam de saúde e doenças.\n",
      "3. \"Amazon anuncia planos para construir um novo centro de distribuição no Texas\" e \"Starbucks apresenta opções de leite vegetal em todas as lojas dos EUA\" - Ambas tratam de empresas e suas atividades.\n",
      "4. \"Cientistas descobrem novas espécies de aves na floresta amazônica\" e \"Conferência global sobre mudanças climáticas será realizada em Paris no próximo mês\" - Ambas tratam de descobertas científicas e eventos globais.\n",
      "\n",
      "Q:\n",
      "Agrupamento:\n",
      "\n",
      "Frases para Agrupar:\n",
      "\n",
      "\"O preço da carne bovina subiu 15% no último mês\"\n",
      "\"O preço da gasolina aumentou 20% nos últimos três meses\"\n",
      "\"O preço da soja caiu 10% neste mês\"\n",
      "\"O preço da madeira aumentou 25% nos últimos seis meses\"\n",
      "\"O preço da lã subiu 18% no último ano\"\n",
      "\"O preço da café cafeia diminuiu 12% nos últimos dois meses\"\n",
      "\"O preço da cobre caiu 15% nos últimos seis meses\"\n",
      "\"O preço da petróleo diminuiu 20% nos últimos dois meses\"\n",
      "\n",
      "Pergunta:\n",
      "Esta é uma tarefa de agrupamento de frases similares\n"
     ]
    }
   ],
   "source": [
    "################# Categorização e Clustering / Agrupamento #################\n",
    "\n",
    "context = \"\"\"\n",
    "Frases para Agrupar:\n",
    "1. \"A produção industrial está em alta este mês.\"\n",
    "2. \"Agricultores relatam uma colheita abundante nesta temporada.\"\n",
    "3. \"O crescimento econômico acelerou no último trimestre.\"\n",
    "\n",
    "Agrupamento:\n",
    "    Frases 1 e 3: Ambas tratam de crescimento econômico.\n",
    "    Frase 2: Trata de agricultura, não se encaixa diretamente com as outras duas sobre economia.\n",
    "\n",
    "Frases para Agrupar:\n",
    "1. \"Pesquisadores descobrem um novo tipo de antibiótico no solo da floresta tropical.\"\n",
    "2. \"A conferência de tecnologia revela inovações em inteligência artificial.\"\n",
    "3. \"Novo método de reciclagem aumenta a eficiência na conversão de resíduos plásticos.\"\n",
    "\n",
    "Agrupamento:\n",
    "    Frase 1: Relacionada a descobertas científicas.\n",
    "    Frases 2 e 3: Relacionadas a inovações tecnológicas.\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Frases para Agrupar:\n",
    "\n",
    "\"As vendas de carros elétricos da Tesla continuam a subir apesar da pandemia\"\n",
    "\"Novo estudo sugere que o consumo de café pode diminuir o risco de doenças cardíacas\"\n",
    "\"O modelo mais recente do iPhone apresenta uma tela maior e câmera aprimorada\"\n",
    "\"Casos de COVID-19 aumentam na Índia, sobrecarregando o sistema de saúde\"\n",
    "\"Amazon anuncia planos para construir um novo centro de distribuição no Texas\"\n",
    "\"Cientistas descobrem novas espécies de aves na floresta amazônica\"\n",
    "\"Conferência global sobre mudanças climáticas será realizada em Paris no próximo mês\"\n",
    "\"Starbucks apresenta opções de leite vegetal em todas as lojas dos EUA\"\n",
    "\n",
    "Pergunta:\n",
    "Esta é uma tarefa de agrupamento de frases similares. Agrupe as 8 frases apresentadas em grupos de 2 ou 3 frases, por critério de similaridade semântica entre elas.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Extrair os tensores de input_ids e da attention_mask\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "input_ids = input_ids.to('cuda')\n",
    "attention_mask = tokens[\"attention_mask\"]\n",
    "\n",
    "# Geração da resposta\n",
    "with torch.no_grad():\n",
    "    generate_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=512,\n",
    "        #do_sample=True,\n",
    "        #top_k=40,\n",
    "    )\n",
    "\n",
    "# Decodificação e impressão da resposta (answer = last_hidden_states)\n",
    "last_hidden_states = tokenizer.decode(generate_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "answer = last_hidden_states\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################################## SUMARIZAÇÃO DE TEXTO ##################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texto: \"A água é essencial para a vida na Terra. Ela não apenas sustenta os organismos vivos, mas também participa de vários processos vitais, como o ciclo hidrológico, que afeta o clima global e as condições meteorológicas.\"\n",
      "Pergunta: Resuma o texto.\n",
      "Resposta: A água é crucial para a vida e processos globais como o clima.\n",
      "\n",
      "Texto: \"As florestas tropicais são ricas em biodiversidade. Elas não só abrigam uma grande variedade de espécies animais e vegetais, mas também ajudam a regular o clima terrestre e são vitais para a manutenção de muitos ecossistemas.\"\n",
      "Pergunta: Resuma o texto.\n",
      "Resposta: Florestas tropicais têm alta biodiversidade e são importantes para o clima e ecossistemas.\n",
      "\n",
      "\n",
      "Q: \n",
      "Texto: \"Sabemos onde realmente está a pipa em nosso coração? Não conseguiremos isso de novo se perdermos isso na vida, talvez nos arrependamos e nos redimamos, mas tudo isso parece ser tarde demais. Sempre que a pipa é lançada no céu, não deveríamos nos perguntar se realmente valorizamos o que temos?\n",
      "Cada um de nós fez algo na juventude que nos envergonhará no futuro. Essas coisas podem ser como uma sombra que o acompanha pelo resto da vida, de modo que você só consegue olhar para ela. Mas o tempo não vai mudar, os seus melhores esforços para compensar isso, como não é uma espécie de auto-ajuda? A beleza e a amizade da infância, por causa de uma negligência covarde e arruinada, se você tiver outra chance, você está disposto a se esforçar para recuperar aquele antigo eu?\n",
      "Mas as pessoas são assim, vivem sempre dentro de um determinado limite de tempo, onde o mundo pode estar alguns anos depois nem elas conseguem entender, mas é isso que não conseguimos superar. Para você, mil vezes, todo o corpo ainda estará justo, talvez isso seja a vida, a vida não é apenas fazer coisas que valem a pena!\"\n",
      "\n",
      "Pergunta: Resuma o texto.\n",
      "\n",
      "A: A mensagem central do texto é a importância de apreciar e cuidar do que temos, pois o tempo passa rápido e não podemos recuperar o tempo perdido. O autor reflete sobre a importância de valorizar a infância e os laços de amizade e beleza que podem ser perdidos devido à negligência ou arruinamento. O texto enfatiza a ideia de que as pessoas são limitadas pelo tempo e que o mundo pode mudar de maneira que elas não podem entender, mas a vida é ainda valiosa por si mesma.\n"
     ]
    }
   ],
   "source": [
    "################# \"World Knowledge\" e Compreensão #################\n",
    "\n",
    "context = \"\"\"\n",
    "Texto: \"A água é essencial para a vida na Terra. Ela não apenas sustenta os organismos vivos, mas também participa de vários processos vitais, como o ciclo hidrológico, que afeta o clima global e as condições meteorológicas.\"\n",
    "Pergunta: Resuma o texto.\n",
    "Resposta: A água é crucial para a vida e processos globais como o clima.\n",
    "\n",
    "Texto: \"As florestas tropicais são ricas em biodiversidade. Elas não só abrigam uma grande variedade de espécies animais e vegetais, mas também ajudam a regular o clima terrestre e são vitais para a manutenção de muitos ecossistemas.\"\n",
    "Pergunta: Resuma o texto.\n",
    "Resposta: Florestas tropicais têm alta biodiversidade e são importantes para o clima e ecossistemas.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "question = \"\"\"\n",
    "Texto: \"Sabemos onde realmente está a pipa em nosso coração? Não conseguiremos isso de novo se perdermos isso na vida, talvez nos arrependamos e nos redimamos, mas tudo isso parece ser tarde demais. Sempre que a pipa é lançada no céu, não deveríamos nos perguntar se realmente valorizamos o que temos?\n",
    "Cada um de nós fez algo na juventude que nos envergonhará no futuro. Essas coisas podem ser como uma sombra que o acompanha pelo resto da vida, de modo que você só consegue olhar para ela. Mas o tempo não vai mudar, os seus melhores esforços para compensar isso, como não é uma espécie de auto-ajuda? A beleza e a amizade da infância, por causa de uma negligência covarde e arruinada, se você tiver outra chance, você está disposto a se esforçar para recuperar aquele antigo eu?\n",
    "Mas as pessoas são assim, vivem sempre dentro de um determinado limite de tempo, onde o mundo pode estar alguns anos depois nem elas conseguem entender, mas é isso que não conseguimos superar. Para você, mil vezes, todo o corpo ainda estará justo, talvez isso seja a vida, a vida não é apenas fazer coisas que valem a pena!\"\n",
    "\n",
    "Pergunta: Resuma o texto.\n",
    "\"\"\"\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Extrair os tensores de input_ids e da attention_mask\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "input_ids = input_ids.to('cuda')\n",
    "attention_mask = tokens[\"attention_mask\"]\n",
    "\n",
    "# Outputs - Passar ambos para o modelo e gerar a resposta (generate_ids = outputs)\n",
    "with torch.no_grad():\n",
    "    generate_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=256,\n",
    "        #do_sample=True,\n",
    "        #top_k=40,\n",
    "    )\n",
    "\n",
    "# Decodificação e impressão da resposta (answer = last_hidden_states)\n",
    "last_hidden_states = tokenizer.decode(generate_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "answer = last_hidden_states\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texto: \"A água é vital para todas as formas de vida conhecidas. A importância da água para os seres vivos é tão grande que ela é considerada uma substância essencial para a existência de vida.\"\n",
      "Pergunta: Resuma o texto.\n",
      "Resposta: A água é crucial para a vida de todos os seres vivos conhecidos.\n",
      "\n",
      "Texto: \"As florestas são essenciais para a saúde do nosso planeta. Elas fornecem oxigênio, abrigam biodiversidade, regulam o clima e oferecem recursos para a vida humana.\"\n",
      "Pergunta: Resuma o texto.\n",
      "Resposta: As florestas desempenham um papel vital no bem-estar do planeta e no suporte à vida.\n",
      "\n",
      "\n",
      "Q: \n",
      "Texto:  \"Escrever é esquecer. A literatura é a maneira mais agradável de ignorar a vida. \n",
      "A música embala, as artes visuais animam, as artes vivas (como a dança e a arte de representar) entretêm. \n",
      "A primeira, porém, afasta-se da vida por fazer dela um sono; as segundas, contudo, não se afastam da vida - umas porque usam de fórmulas visíveis e portanto vitais, outras porque vivem da mesma vida humana.\n",
      "Não é o caso da literatura. Essa simula a vida. Um romance é uma história do que nunca foi e um drama é um romance dado sem narrativa. \n",
      "Um poema é a expressão de ideias ou de sentimentos em linguagem que ninguém emprega, pois que ninguém fala em verso.\"\n",
      "Fernando Pessoa\n",
      "\n",
      "Pergunta: Resuma o texto.\n",
      "\n",
      "A: Escrever é esquecer, a literatura simula a vida, enquanto as artes vivas e as artes visuais animam e entretêm, pois as primeiras se afastam da vida por fazer dela um sono, enquanto as segundas não se afastam da vida, pois usam de fórmulas vitais ou vivem da mesma vida humana. Um romance é uma história do que nunca foi e um drama é um romance dado sem narrativa, enquanto um poema é a expressão de ideias ou de sentimentos em linguagem que ninguém emprega, pois que ninguém fala em verso. (Fernando Pessoa)\n"
     ]
    }
   ],
   "source": [
    "################# Sumarização de Texto #################\n",
    "################# \"World Knowledge\" e Compreensão #################\n",
    "\n",
    "context = \"\"\"\n",
    "Texto: \"A água é vital para todas as formas de vida conhecidas. A importância da água para os seres vivos é tão grande que ela é considerada uma substância essencial para a existência de vida.\"\n",
    "Pergunta: Resuma o texto.\n",
    "Resposta: A água é crucial para a vida de todos os seres vivos conhecidos.\n",
    "\n",
    "Texto: \"As florestas são essenciais para a saúde do nosso planeta. Elas fornecem oxigênio, abrigam biodiversidade, regulam o clima e oferecem recursos para a vida humana.\"\n",
    "Pergunta: Resuma o texto.\n",
    "Resposta: As florestas desempenham um papel vital no bem-estar do planeta e no suporte à vida.\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Texto:  \"Escrever é esquecer. A literatura é a maneira mais agradável de ignorar a vida. \n",
    "A música embala, as artes visuais animam, as artes vivas (como a dança e a arte de representar) entretêm. \n",
    "A primeira, porém, afasta-se da vida por fazer dela um sono; as segundas, contudo, não se afastam da vida - umas porque usam de fórmulas visíveis e portanto vitais, outras porque vivem da mesma vida humana.\n",
    "Não é o caso da literatura. Essa simula a vida. Um romance é uma história do que nunca foi e um drama é um romance dado sem narrativa. \n",
    "Um poema é a expressão de ideias ou de sentimentos em linguagem que ninguém emprega, pois que ninguém fala em verso.\"\n",
    "Fernando Pessoa\n",
    "\n",
    "Pergunta: Resuma o texto.\n",
    "\"\"\"\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Extrair os tensores de input_ids e da attention_mask\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "input_ids = input_ids.to('cuda')\n",
    "attention_mask = tokens[\"attention_mask\"]\n",
    "\n",
    "# Outputs - Passar ambos para o modelo e gerar a resposta (generate_ids = outputs)\n",
    "with torch.no_grad():\n",
    "    generate_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=256,\n",
    "        #do_sample=True,\n",
    "        #top_k=40,\n",
    "    )\n",
    "\n",
    "# Decodificação e impressão da resposta (answer = last_hidden_states)\n",
    "last_hidden_states = tokenizer.decode(generate_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "answer = last_hidden_states\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########################################### TRANSFORMAÇÃO DE FORMATOS  ###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transforme a frase, que está na terceira pessoa, em frase em primeira pessoa: Silva acredita em outra coisa. De acordo com sua pesquisa, as declarações anteriores sobre este assunto estão incorretas.\n",
      "Resposta: Acredito em outra coisa, disse Silva. De acordo com a minha pesquisa, as declarações anteriores sobre este assunto estão incorretas.\n",
      "\n",
      "\n",
      "Q: \n",
      "Transforme a frase, que está na terceira pessoa, em frase em primeira pessoa:\n",
      "Apesar dos desafios envolvidos, os pesquisadores continuam a defender as suas reivindicações.\n",
      "\n",
      "A: \n",
      "Embora sejam envolvidos desafios, continuo a defender as minhas reivindicações como pesquisador.\n",
      "\n",
      "\n",
      "Q: \n",
      "Transforme a frase, que está na terceira pessoa, em frase em primeira pessoa:\n",
      "A maioria das pessoas que conheço são honestas.\n",
      "\n",
      "A: \n",
      "A maioria das pessoas que conheço é comp\n"
     ]
    }
   ],
   "source": [
    "################# Converter uma frase na terceira pessoa  para a primeira pessoa #################\n",
    "\n",
    "context = \"\"\"\n",
    "Transforme a frase, que está na terceira pessoa, em frase em primeira pessoa: Silva acredita em outra coisa. De acordo com sua pesquisa, as declarações anteriores sobre este assunto estão incorretas.\n",
    "Resposta: Acredito em outra coisa, disse Silva. De acordo com a minha pesquisa, as declarações anteriores sobre este assunto estão incorretas.\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Transforme a frase, que está na terceira pessoa, em frase em primeira pessoa:\n",
    "Apesar dos desafios envolvidos, os pesquisadores continuam a defender as suas reivindicações.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Extrair os tensores de input_ids e da attention_mask\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "input_ids = input_ids.to('cuda')\n",
    "attention_mask = tokens[\"attention_mask\"]\n",
    "\n",
    "# Outputs - Passar ambos para o modelo e gerar a resposta (generate_ids = outputs)\n",
    "with torch.no_grad():\n",
    "    generate_ids = model.generate(\n",
    "        input_ids=input_ids,GSM8K\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=100,\n",
    "        #do_sample=True,\n",
    "        #top_k=40,\n",
    "    )\n",
    "\n",
    "# Decodificação e impressão da resposta (answer = last_hidden_states)\n",
    "last_hidden_states = tokenizer.decode(generate_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "answer = last_hidden_states\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tales from Shakespeare is an English children's book written by Charles Lamb and his sister Mary Lamb in 1807. The book is designed to make the stories of Shakespeare's plays familiar to the young. However, as noted in the author's Preface, \"[Shakespeare's] words are used whenever it seemed possible to bring them in; and in whatever has been added to give them the regular form of a connected story, diligent care has been taken to select such words as might least interrupt the effect of the beautiful English tongue in which he wrote: therefore, words introduced into our language since his time have been as far as possible avoided.\" \n",
      "\n",
      "\n",
      "Q: \n",
      "Traduza o parágrafo abaixo para o português brasileiro\n",
      "\n",
      "A: \n",
      "Tradução: O livro Tales from Shakespeare, escrito por Charles Lamb e sua irmã Mary Lamb em 1807, tem como objetivo familiarizar as histórias das peças de Shakespeare com crianças. No entanto, como nota no prefácio do autor, \"as palavras dele são usadas sempre que foi possível introduzi-las; e em tudo o que foi adicionado para dar-lhes a forma de uma história conectada, cuidadosa atenção foi tomada para selecionar palavras que menos interromperam o efe da linda língua inglesa em que ele escreveu: portanto, as palavras introduzidas na nossa língua desde o seu tempo foram, o mais possível, evitadas.\"\n"
     ]
    }
   ],
   "source": [
    "################# Machine Translation #################\n",
    "\n",
    "\n",
    "context = \"\"\"\n",
    "Tales from Shakespeare is an English children's book written by Charles Lamb and his sister Mary Lamb in 1807. The book is designed to make the stories of Shakespeare's plays familiar to the young. However, as noted in the author's Preface, \"[Shakespeare's] words are used whenever it seemed possible to bring them in; and in whatever has been added to give them the regular form of a connected story, diligent care has been taken to select such words as might least interrupt the effect of the beautiful English tongue in which he wrote: therefore, words introduced into our language since his time have been as far as possible avoided.\" \n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Traduza o parágrafo abaixo para o português brasileiro\n",
    "\"\"\"\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Extrair os tensores de input_ids e da attention_mask\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "input_ids = input_ids.to('cuda')\n",
    "attention_mask = tokens[\"attention_mask\"]\n",
    "\n",
    "# Outputs - Passar ambos para o modelo e gerar a resposta (generate_ids = outputs)\n",
    "with torch.no_grad():\n",
    "    generate_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=256,\n",
    "        #do_sample=True,\n",
    "        #top_k=40,\n",
    "    )\n",
    "\n",
    "# Decodificação e impressão da resposta (answer = last_hidden_states)\n",
    "last_hidden_states = tokenizer.decode(generate_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "answer = last_hidden_states\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "As Seller, an encyclopedia salesman, approached the grounds on which the house of Hermit, the hermit, was situated, he saw a sign that said, \"No salesmen. Trespassers will be prosecuted. Proceed at your own risk.\"\n",
      "Although Seller had not been invited to enter, he ignored the sign and drove up the driveway toward the house. As he rounded a curve, a powerful explosive charge buried in the driveway exploded, and Seller was injured. \n",
      "\n",
      "\n",
      "\n",
      "Q: \n",
      "Traduza o parágrafo para o português.\n",
      "\n",
      "\n",
      "A: \n",
      "Enquanto o Vendedor, um vendedor de enciclopédias, se aproximava das terras onde a casa do Ermitão, o ermitão, estava situada, viu um cartaz que dizia: \"Nenhum vendedor. Intrusos serão processados. Procedam a seu risco.\"\n",
      "\n",
      "Apesar de não ter sido convidado a entrar, ele ignorou o cartaz e seguiu pela estrada até a casa. Enquanto redondo uma curva, uma poderosa carga explosiva enterrada na estrada explodiu, e o Vendedor foi ferido.\n"
     ]
    }
   ],
   "source": [
    "################# TRANSORMAÇÃO DE FORMATOS  #################\n",
    "\n",
    "\n",
    "context = \"\"\"\n",
    "As Seller, an encyclopedia salesman, approached the grounds on which the house of Hermit, the hermit, was situated, he saw a sign that said, \"No salesmen. Trespassers will be prosecuted. Proceed at your own risk.\"\n",
    "Although Seller had not been invited to enter, he ignored the sign and drove up the driveway toward the house. As he rounded a curve, a powerful explosive charge buried in the driveway exploded, and Seller was injured. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Traduza o parágrafo para o português.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Extrair os tensores de input_ids e da attention_mask\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "input_ids = input_ids.to('cuda')\n",
    "attention_mask = tokens[\"attention_mask\"]\n",
    "\n",
    "# Outputs - Passar ambos para o modelo e gerar a resposta (generate_ids = outputs)\n",
    "with torch.no_grad():\n",
    "    generate_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=256,\n",
    "        #do_sample=True,\n",
    "        #top_k=40,\n",
    "    )\n",
    "\n",
    "# Decodificação e impressão da resposta (answer = last_hidden_states)\n",
    "last_hidden_states = tokenizer.decode(generate_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "answer = last_hidden_states\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"Um pedestre atravessou a rua fora da faixa de pedestres e foi atingido por um carro. O motorista estava acima do limite de velocidade.\"\n",
      "Pergunta: O motorista é responsável pelos ferimentos do pedestre?\n",
      "(A) Sim, porque ele estava acima do limite de velocidade.\n",
      "(B) Não, porque o pedestre não estava na faixa.\n",
      "Resposta: (A) Sim, porque ele estava acima do limite de velocidade.\n",
      "Justificativa: Apesar de o pedestre não estar na faixa, o motorista tem a responsabilidade final de controlar a velocidade do veículo para evitar acidentes, o que é uma expectativa legal padrão.\n",
      "\n",
      "\"Um cliente escorrega e cai em uma loja onde um sinal de 'Piso Molhado' estava claramente visível.\"\n",
      "Pergunta: A loja é responsável pelos ferimentos do cliente?\n",
      "(A) Sim, porque é responsabilidade da loja manter um ambiente seguro.\n",
      "(B) Não, porque o sinal de aviso estava visível.\n",
      "Resposta: (B) Não, porque o sinal de aviso estava visível.\n",
      "Justificativa: A presença de um aviso claro reduz a responsabilidade da loja, pois isso significa que o cliente foi devidamente informado sobre o perigo potencial.\n",
      "\n",
      "\n",
      "Q: \n",
      "Can Seller recover damages from Hermit for his injuries?\n",
      "(A) Yes, unless Hermit, when he planted the charge, intended only to deter, not harm, intruders.\n",
      "(B) Yes, if Hermit was responsible for the explosive charge under the driveway.\n",
      "(C) No, because Seller ignored the sign, which warned him against proceeding further.\n",
      "(D) No, if Hermit reasonably feared that intruders would come and harm him or his family.\n",
      "\n",
      "Justifique a escolha da alternativa correta entre as quatro apresentadas (A, B, C ou D).\n",
      "\n",
      "A: Yes, unless Hermit, when he planted the charge, intended only to deter, not harm, intruders.\n",
      "\n",
      "B: Yes, if Hermit was responsible for the explosive charge under the driveway.\n",
      "\n",
      "C: No, because Seller ignored the sign, which warned him against proceeding further.\n",
      "\n",
      "D: No, if Hermit reasonably feared that intruders would come and harm him or his family.\n",
      "\n",
      "Justificativa: A alternativa correta é A. A responsabilidade do danos é do vendedor, a menos que o hermit, ao plantar a carga, tivesse a intenção apenas de deter, e não de ferir, os intrusos. Isso significa que se o hermit tivesse a intenção apenas de deter os intrusos, e não de feri-los, ele não seria responsável pelos danos causados ao vendedor.\n",
      "\n",
      "B alternativa correta é B. A responsabilidade do danos é do vendedor, se o hermit foi responsável pela carga explosiva localizada sob o driveway.\n",
      "\n",
      "C alternativa correta é\n"
     ]
    }
   ],
   "source": [
    "################# TRANSORMAÇÃO DE FORMATOS E ICL com self-reflection  #################\n",
    "\n",
    "context = \"\"\"\n",
    "\"Um pedestre atravessou a rua fora da faixa de pedestres e foi atingido por um carro. O motorista estava acima do limite de velocidade.\"\n",
    "Pergunta: O motorista é responsável pelos ferimentos do pedestre?\n",
    "(A) Sim, porque ele estava acima do limite de velocidade.\n",
    "(B) Não, porque o pedestre não estava na faixa.\n",
    "Resposta: (A) Sim, porque ele estava acima do limite de velocidade.\n",
    "Justificativa: Apesar de o pedestre não estar na faixa, o motorista tem a responsabilidade final de controlar a velocidade do veículo para evitar acidentes, o que é uma expectativa legal padrão.\n",
    "\n",
    "\"Um cliente escorrega e cai em uma loja onde um sinal de 'Piso Molhado' estava claramente visível.\"\n",
    "Pergunta: A loja é responsável pelos ferimentos do cliente?\n",
    "(A) Sim, porque é responsabilidade da loja manter um ambiente seguro.\n",
    "(B) Não, porque o sinal de aviso estava visível.\n",
    "Resposta: (B) Não, porque o sinal de aviso estava visível.\n",
    "Justificativa: A presença de um aviso claro reduz a responsabilidade da loja, pois isso significa que o cliente foi devidamente informado sobre o perigo potencial.\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Can Seller recover damages from Hermit for his injuries?\n",
    "(A) Yes, unless Hermit, when he planted the charge, intended only to deter, not harm, intruders.\n",
    "(B) Yes, if Hermit was responsible for the explosive charge under the driveway.\n",
    "(C) No, because Seller ignored the sign, which warned him against proceeding further.\n",
    "(D) No, if Hermit reasonably feared that intruders would come and harm him or his family.\n",
    "\n",
    "Justifique a escolha da alternativa correta entre as quatro apresentadas (A, B, C ou D).\n",
    "\"\"\"\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Extrair os tensores de input_ids e da attention_mask\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "input_ids = input_ids.to('cuda')\n",
    "attention_mask = tokens[\"attention_mask\"]\n",
    "\n",
    "# Outputs - Passar ambos para o modelo e gerar a resposta (generate_ids = outputs)\n",
    "with torch.no_grad():\n",
    "    generate_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=256,\n",
    "        #do_sample=True,\n",
    "        #top_k=40,\n",
    "    )\n",
    "\n",
    "# Decodificação e impressão da resposta (answer = last_hidden_states)\n",
    "last_hidden_states = tokenizer.decode(generate_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "answer = last_hidden_states\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Esta é uma tarefa de retirada de referências bibliográficas do texto. As referências estão escritas no formato \"[número]\". Exemplo: [10].\n",
      "\n",
      "Exemplos:\n",
      "Contexto: Joao da silva era carpinteiro [1][24]. Estudou na escola santa amelia [17] até os 18 anos de idade.\n",
      "Resposta: Joao da silva era carpinteiro. Estudou na escola santa amelia até os 18 anos de idade.\n",
      "Contexto: Ontem foi dia de ramos [32].\n",
      "Resposta: Ontem foi dia de ramos.\n",
      "\n",
      "\n",
      "Q: \n",
      "Contexto: José Bonifácio foi destituído de sua posição em dezembro de 1833 e substituído por outro tutor.[31][32][33] D. Pedro II passava os dias estudando,[34] com apenas duas horas livres para recreação.[35] Acordava às 06h30 da manhã e começava seus estudos às sete, continuando até as dez da noite, quando ia para cama.[36] Tomou-se grande cuidado em sua educação para formar valores e personalidade diferente da impulsividade e irresponsabilidade demonstradas por seu pai.[31][37] Sua paixão pela leitura lhe permitiu assimilar qualquer informação.[38] D. Pedro II não era um gênio,[39] mas inteligente[40] e com grande capacidade para acumular conhecimento facilmente.[41]\n",
      "\n",
      "Remova do texeto as referências no formato \"[número]\" e escreva a Resposta:\n",
      "\n",
      "\n",
      "A: José Bonifácio foi destituído de sua posição em dezembro de 1833 e substituído por outro tutor. D. Pedro II passava os dias estudando, com apenas duas horas livres para recreação. Acordava às 06h30 da manhã e começava seus estudos às sete, continuando até as dez da noite, quando ia para cama. Tomou-se grande cuidado em sua educação para formar valores e personalidade diferente da impulsividade e irresponsabilidade demonstradas por seu pai. Sua paixão pela leitura lhe permitiu assimilar qualquer informação. D. Pedro II não era um gênio, mas inteligente e com grande capacidade para acumular conhecimento facilmente.\n"
     ]
    }
   ],
   "source": [
    "################# Retirar Referências do Texto #################\n",
    "\n",
    "context = \"\"\"\n",
    "\n",
    "Esta é uma tarefa de retirada de referências bibliográficas do texto. As referências estão escritas no formato \"[número]\". Exemplo: [10].\n",
    "\n",
    "Exemplos:\n",
    "Contexto: Joao da silva era carpinteiro [1][24]. Estudou na escola santa amelia [17] até os 18 anos de idade.\n",
    "Resposta: Joao da silva era carpinteiro. Estudou na escola santa amelia até os 18 anos de idade.\n",
    "Contexto: Ontem foi dia de ramos [32].\n",
    "Resposta: Ontem foi dia de ramos.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "question = \"\"\"\n",
    "Contexto: José Bonifácio foi destituído de sua posição em dezembro de 1833 e substituído por outro tutor.[31][32][33] D. Pedro II passava os dias estudando,[34] com apenas duas horas livres para recreação.[35] Acordava às 06h30 da manhã e começava seus estudos às sete, continuando até as dez da noite, quando ia para cama.[36] Tomou-se grande cuidado em sua educação para formar valores e personalidade diferente da impulsividade e irresponsabilidade demonstradas por seu pai.[31][37] Sua paixão pela leitura lhe permitiu assimilar qualquer informação.[38] D. Pedro II não era um gênio,[39] mas inteligente[40] e com grande capacidade para acumular conhecimento facilmente.[41]\n",
    "\n",
    "Remova do texeto as referências no formato \"[número]\" e escreva a Resposta:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Extrair os tensores de input_ids e da attention_mask\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "input_ids = input_ids.to('cuda')\n",
    "attention_mask = tokens[\"attention_mask\"]\n",
    "\n",
    "# Outputs - Passar ambos para o modelo e gerar a resposta (generate_ids = outputs)\n",
    "with torch.no_grad():\n",
    "    generate_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=256,\n",
    "        #do_sample=True,\n",
    "        #top_k=40,\n",
    "    )\n",
    "\n",
    "# Decodificação e impressão da resposta (answer = last_hidden_states)\n",
    "last_hidden_states = tokenizer.decode(generate_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "answer = last_hidden_states\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################################# EXTRAÇÃO DE CONTEÚDO  #############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A Grande Barreira de Corais é o maior sistema de recifes de corais do mundo, composto por mais de 2.900 recifes individuais e 900 ilhas que se estendem por mais de 2.300 quilômetros. Está localizado no Mar de Coral, na costa da Austrália. O recife abriga uma grande variedade de vida marinha, incluindo mais de 1.500 espécies de peixes, 600 tipos de corais e inúmeras outras espécies.\n",
      "\n",
      "Pergunta: Qual é o maior sistema de recifes de corais do mundo?\n",
      "Resposta: A Grande Barreira de Corais é o maior sistema de recifes de corais do mundo.\n",
      "\n",
      "Pergunta: Quantas espécies de peixes podem ser encontradas na Grande Barreira de Corais?\n",
      "Resposta: Mais de 1.500 espécies de peixes podem ser encontradas na Grande Barreira de Corais.\n",
      "\n",
      "\n",
      "Q: \n",
      "Dada a descrição do contexto acima:\n",
      "O que é a Grande Barreira de Corais e onde ela está localizada?\n",
      "\n",
      "A: A Grande Barreira de Corais é o maior sistema de recifes de corais do mundo, composto por mais de 2.900 recifes individuais e 900 ilhas que se estendem por mais de 2.300 quilômetros, e está localizada no Mar de Coral, na costa da Austrália.\n",
      "\n",
      "\n",
      "Q: \n",
      "Qual é o número total de recifes e ilhas que compõem a Grande Barreira de Corais?\n",
      "\n",
      "A: A Grande Barreira de Corais é composta por mais de 2.900 recifes individuais e 900 ilhas.\n",
      "\n",
      "\n",
      "Q\n"
     ]
    }
   ],
   "source": [
    "################# Extração de Conteúdo #################\n",
    "\n",
    "context = \"\"\"\n",
    "A Grande Barreira de Corais é o maior sistema de recifes de corais do mundo, composto por mais de 2.900 recifes individuais e 900 ilhas que se estendem \\\n",
    "por mais de 2.300 quilômetros. Está localizado no Mar de Coral, na costa da Austrália. \\\n",
    "O recife abriga uma grande variedade de vida marinha, incluindo mais de 1.500 espécies de peixes, 600 tipos de corais e inúmeras outras espécies.\n",
    "\n",
    "Pergunta: Qual é o maior sistema de recifes de corais do mundo?\n",
    "Resposta: A Grande Barreira de Corais é o maior sistema de recifes de corais do mundo.\n",
    "\n",
    "Pergunta: Quantas espécies de peixes podem ser encontradas na Grande Barreira de Corais?\n",
    "Resposta: Mais de 1.500 espécies de peixes podem ser encontradas na Grande Barreira de Corais.\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Dada a descrição do contexto acima:\n",
    "O que é a Grande Barreira de Corais e onde ela está localizada?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Extrair os tensores de input_ids e da attention_mask\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "input_ids = input_ids.to('cuda')\n",
    "attention_mask = tokens[\"attention_mask\"]\n",
    "\n",
    "# Geração da resposta\n",
    "with torch.no_grad():\n",
    "    generate_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=160,\n",
    "        #do_sample=True,\n",
    "        #top_k=40,\n",
    "    )\n",
    "\n",
    "# Decodificação e impressão da resposta (answer = last_hidden_states)\n",
    "last_hidden_states = tokenizer.decode(generate_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "answer = last_hidden_states\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texto de Referência:\n",
      "O Brasil é o quinto maior país do mundo em território, com uma área total de 8.515.767 quilômetros quadrados. É também o quinto país mais populoso do mundo, com uma população estimada em cerca de 211 milhões de pessoas em 2021. O país é conhecido por sua diversidade cultural e natural, incluindo a floresta Amazônica, que é a maior floresta tropical do mundo.\n",
      "Pergunta: Qual a dimensão do Brasil em área?\n",
      "Resposta: 8.515.767 quilômetros quadrados.\n",
      "\n",
      "\n",
      "\n",
      "Q: \n",
      "Texto de Referência:\n",
      "O Brasil é o quinto maior país do mundo em território, com uma área total de 8.515.767 quilômetros quadrados. É também o quinto país mais populoso do mundo, com uma população estimada em cerca de 211 milhões de pessoas em 2021. O país é conhecido por sua diversidade cultural e natural, incluindo a floresta Amazônica, que é a maior floresta tropical do mundo.\n",
      "Pergunta: Qual é a posição do Brasil em termos de tamanho de território e população, e qual é a principal característica natural mencionada no texto?\n",
      "\n",
      "A: O Brasil é o quinto maior país do mundo em território e população, e a principal característica natural mencionada no texto é a Floresta Amazônica, que é a maior floresta tropical do mundo.\n",
      "\n",
      "\n",
      "\n",
      "Q: \n",
      "Texto de Referência:\n",
      "O Brasil é o maior produtor mundial de soja, arroz, café e suco de cana-de-açúcar. Em 2019, o país foi o segundo maior exportador de soja, o terceiro maior exportador de carne bovina e o quarto maior exportador de carne suína. O Brasil também é um dos principais produtores mundiais de ouro, ferro, bauxita e manganês.\n",
      "\n",
      "Pergunta: Qual é o principal produto agrícola do Brasil, e qual é a posição do país no comércio mundial de soja?\n",
      "\n",
      "A: O principal produto agrícola do Brasil é a soja, e em 2019, o país foi o maior produtor\n"
     ]
    }
   ],
   "source": [
    "################# Reconhecimento e Extração de Informações Específicas #################\n",
    "\n",
    "context = \"\"\"\n",
    "Texto de Referência:\n",
    "O Brasil é o quinto maior país do mundo em território, com uma área total de 8.515.767 quilômetros quadrados. É também o quinto país mais populoso do mundo, \\\n",
    "com uma população estimada em cerca de 211 milhões de pessoas em 2021. \\\n",
    "O país é conhecido por sua diversidade cultural e natural, incluindo a floresta Amazônica, que é a maior floresta tropical do mundo.\n",
    "Pergunta: Qual a dimensão do Brasil em área?\n",
    "Resposta: 8.515.767 quilômetros quadrados.\n",
    "\n",
    "\"\"\"\n",
    "question = \"\"\"\n",
    "Texto de Referência:\n",
    "O Brasil é o quinto maior país do mundo em território, com uma área total de 8.515.767 quilômetros quadrados. É também o quinto país mais populoso do mundo, com uma população estimada em cerca de 211 milhões de pessoas em 2021. O país é conhecido por sua diversidade cultural e natural, incluindo a floresta Amazônica, que é a maior floresta tropical do mundo.\n",
    "Pergunta: Qual é a posição do Brasil em termos de tamanho de território e população, e qual é a principal característica natural mencionada no texto?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Extrair os tensores de input_ids e da attention_mask\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "input_ids = input_ids.to('cuda')\n",
    "attention_mask = tokens[\"attention_mask\"]\n",
    "\n",
    "# Outputs - Passar ambos para o modelo e gerar a resposta (generate_ids = outputs)\n",
    "with torch.no_grad():\n",
    "    generate_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=256,\n",
    "        #do_sample=True,\n",
    "        #top_k=40,\n",
    "    )\n",
    "\n",
    "# Decodificação e impressão da resposta (answer = last_hidden_states)\n",
    "last_hidden_states = tokenizer.decode(generate_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "answer = last_hidden_states\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Q: \n",
      "Olá\n",
      "Passei algum tempo analisando sua documentação, mas não consegui descobrir como adicionar um novo cartão de crédito.\n",
      "É um problema porque meu cartão atual irá expirar em breve e temo que isso cause uma interrupção no serviço.\n",
      "Como posso atualizar meu cartão de crédito?\n",
      "Desde já, obrigado,\n",
      "João Baião\n",
      "\n",
      "Classifique a intenção presente no texto.\n",
      "\n",
      "A: \n",
      "O intencional do autor é pedir ajuda para adicionar um novo cartão de crédito devido ao próximo vencimento do cartão atual, o que pode causar uma interrupção no serviço.\n",
      "\n",
      "Q: \n",
      "Olá,\n",
      "\n",
      "Passei algum tempo analisando sua documentação, mas não consegui descobrir como adicionar um novo cartão de crédito.\n",
      "\n",
      "É um problema porque meu cartão atual irá expirar em breve e temo que isso cause uma interrupção no serviço.\n",
      "\n",
      "Como posso atualizar meu cartão de crédito?\n",
      "\n",
      "Desde já, obrigado,\n",
      "João Baião\n",
      "\n",
      "Classifique a intenção presente no texto.\n",
      "\n",
      "A: \n",
      "O intencional do autor é pedir ajuda para adicionar um novo cartão de crédito devido ao próximo vencimento do cartão atual, o que pode causar uma interrupção no serviço.\n",
      "\n",
      "Q: \n",
      "Olá\n"
     ]
    }
   ],
   "source": [
    "################# Classificação de Intenções #################\n",
    "\n",
    "context = \"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Olá\n",
    "Passei algum tempo analisando sua documentação, mas não consegui descobrir como adicionar um novo cartão de crédito.\n",
    "É um problema porque meu cartão atual irá expirar em breve e temo que isso cause uma interrupção no serviço.\n",
    "Como posso atualizar meu cartão de crédito?\n",
    "Desde já, obrigado,\n",
    "João Baião\n",
    "\n",
    "Classifique a intenção presente no texto.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Extrair os tensores de input_ids e da attention_mask\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "input_ids = input_ids.to('cuda')\n",
    "attention_mask = tokens[\"attention_mask\"]\n",
    "\n",
    "# Outputs - Passar ambos para o modelo e gerar a resposta (generate_ids = outputs)\n",
    "with torch.no_grad():\n",
    "    generate_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=256,\n",
    "        #do_sample=True,\n",
    "        #top_k=40,\n",
    "    )\n",
    "\n",
    "# Decodificação e impressão da resposta (answer = last_hidden_states)\n",
    "last_hidden_states = tokenizer.decode(generate_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "answer = last_hidden_states\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texto:\n",
      "\"Estou tendo problemas para fazer login na minha conta, e já tentei redefinir minha senha várias vezes sem sucesso. O que mais eu posso fazer para resolver isso?\"\n",
      "Intenção: Solicitar assistência técnica.\n",
      "\n",
      "Texto:\n",
      "\"Acabei de receber o produto que comprei de vocês, e estou muito satisfeito com a qualidade. Quero agradecer e dizer que continuarei sendo um cliente fiel.\"\n",
      "Intenção: Expressar satisfação e gratidão.\n",
      "\n",
      "\n",
      "\n",
      "Q: \n",
      "Olá\n",
      "Passei algum tempo analisando sua documentação, mas não consegui descobrir como adicionar um novo cartão de crédito.\n",
      "É um problema porque meu cartão atual irá expirar em breve e temo que isso cause uma interrupção no serviço.\n",
      "Como posso atualizar meu cartão de crédito?\n",
      "Desde já, obrigado,\n",
      "João Baião\n",
      "\n",
      "Classifique a intenção presente no texto.\n",
      "\n",
      "A: \n",
      "A intenção presente no texto é solicitar assistência técnica.\n",
      "\n",
      "\n",
      "\n",
      "Q: \n",
      "Olá,\n",
      "\n",
      "Eu estou muito satisfeito com o serviço que vocês estão prestando.\n",
      "\n",
      "Eu quero agradecer e dizer que continuarei sendo um cliente fiel.\n",
      "\n",
      "Desde já, obrigado,\n",
      "\n",
      "João Baião\n",
      "\n",
      "Classifique a intenção presente no texto.\n",
      "\n",
      "A: \n",
      "A intenção presente no texto é expressar satisfação e gratidão.\n",
      "\n",
      "\n",
      "\n",
      "Q: \n",
      "Olá,\n",
      "\n",
      "Eu estou tendo problemas para fazer login na minha conta, e já tentei redefinir minha senha várias vezes sem sucesso.\n",
      "\n",
      "O que mais eu posso fazer para resolver isso?\n",
      "\n",
      "Desde já, obrigado,\n",
      "\n",
      "João Baião\n",
      "\n",
      "Classifique a intenção presente no texto.\n",
      "\n",
      "A: \n",
      "A intenção presente no\n"
     ]
    }
   ],
   "source": [
    "################# Classificação de Intenções #################\n",
    "\n",
    "context = \"\"\"\n",
    "Texto:\n",
    "\"Estou tendo problemas para fazer login na minha conta, e já tentei redefinir minha senha várias vezes sem sucesso. O que mais eu posso fazer para resolver isso?\"\n",
    "Intenção: Solicitar assistência técnica.\n",
    "\n",
    "Texto:\n",
    "\"Acabei de receber o produto que comprei de vocês, e estou muito satisfeito com a qualidade. Quero agradecer e dizer que continuarei sendo um cliente fiel.\"\n",
    "Intenção: Expressar satisfação e gratidão.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Olá\n",
    "Passei algum tempo analisando sua documentação, mas não consegui descobrir como adicionar um novo cartão de crédito.\n",
    "É um problema porque meu cartão atual irá expirar em breve e temo que isso cause uma interrupção no serviço.\n",
    "Como posso atualizar meu cartão de crédito?\n",
    "Desde já, obrigado,\n",
    "João Baião\n",
    "\n",
    "Classifique a intenção presente no texto.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Extrair os tensores de input_ids e da attention_mask\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "input_ids = input_ids.to('cuda')\n",
    "attention_mask = tokens[\"attention_mask\"]\n",
    "\n",
    "# Outputs - Passar ambos para o modelo e gerar a resposta (generate_ids = outputs)\n",
    "with torch.no_grad():\n",
    "    generate_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=256,\n",
    "        #do_sample=True,\n",
    "        #top_k=40,\n",
    "    )\n",
    "\n",
    "# Decodificação e impressão da resposta (answer = last_hidden_states)\n",
    "last_hidden_states = tokenizer.decode(generate_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "answer = last_hidden_states\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texto:\n",
      "\"A Microsoft, fundada por Bill Gates e Paul Allen, está sediada em Redmond, Washington.\"\n",
      "\n",
      "Análise:\n",
      "{\n",
      "  \"pessoa\": [\"Bill Gates\", \"Paul Allen\"],\n",
      "  \"lugar\": [\"Redmond\", \"Washington\"],\n",
      "  \"organização\": [\"Microsoft\"]\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "Q: \n",
      "O evento da Apple aconteceu no Steve Jobs Theatre em Cupertino, Califórnia. \n",
      "Tim Cook, CEO da Apple, apresentou o novo iPhone 15, que estará disponível para pré-encomenda a partir da próxima semana. \n",
      "O telefone vem em várias cores, apresenta um processador mais rápido e maior duração da bateria.\n",
      "\n",
      "Analise o parágrafo, identifique em formato JSON Somente as entidades (\"entities\") dos tipos \"pessoa\", \"lugar\" e \"organização\" mencionadas no texto.\n",
      "\n",
      "A:\n",
      "{\n",
      "  \"organização\": [\"Apple\"],\n",
      "  \"lugar\": [\"Cupertino\", \"Califórnia\"],\n",
      "  \"pessoa\": [\"Tim Cook\"]\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "Q:\n",
      "O evento da Apple aconteceu no Steve Jobs Theatre em Cupertino, Califórnia. \n",
      "Tim Cook, CEO da Apple, apresentou o novo iPhone 15, que estará disponível para pré-encomenda a partir da próxima semana. \n",
      "O telefone vem em várias cores, apresenta um processador mais rápido e maior duração da bateria.\n",
      "\n",
      "Analise o parágrafo, identifique em formato JSON Somente as entidades (\"entities\") dos tipos \"pessoa\", \"lugar\" e \"organização\" mencionadas no texto, e também identifique as entidades do tipo \"data\" (data de lançamento do iPhone 15).\n",
      "\n",
      "A:\n",
      "{\n",
      "  \"organização\": [\"Apple\"],\n",
      "  \"lugar\": [\"Cupertino\n"
     ]
    }
   ],
   "source": [
    "################# Reconhecimento e Extração de Entidades #################\n",
    "\n",
    "\n",
    "context = \"\"\"\n",
    "Texto:\n",
    "\"A Microsoft, fundada por Bill Gates e Paul Allen, está sediada em Redmond, Washington.\"\n",
    "\n",
    "Análise:\n",
    "{\n",
    "  \"pessoa\": [\"Bill Gates\", \"Paul Allen\"],\n",
    "  \"lugar\": [\"Redmond\", \"Washington\"],\n",
    "  \"organização\": [\"Microsoft\"]\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "O evento da Apple aconteceu no Steve Jobs Theatre em Cupertino, Califórnia. \n",
    "Tim Cook, CEO da Apple, apresentou o novo iPhone 15, que estará disponível para pré-encomenda a partir da próxima semana. \n",
    "O telefone vem em várias cores, apresenta um processador mais rápido e maior duração da bateria.\n",
    "\n",
    "Analise o parágrafo, identifique em formato JSON Somente as entidades (\"entities\") dos tipos \"pessoa\", \"lugar\" e \"organização\" mencionadas no texto.\n",
    "\"\"\"\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Extrair os tensores de input_ids e da attention_mask\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "input_ids = input_ids.to('cuda')\n",
    "attention_mask = tokens[\"attention_mask\"]\n",
    "\n",
    "# Outputs - Passar ambos para o modelo e gerar a resposta (generate_ids = outputs)\n",
    "with torch.no_grad():\n",
    "    generate_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=256,\n",
    "        #do_sample=True,\n",
    "        #top_k=40,\n",
    "    )\n",
    "\n",
    "# Decodificação e impressão da resposta (answer = last_hidden_states)\n",
    "last_hidden_states = tokenizer.decode(generate_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "answer = last_hidden_states\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texto:\n",
      "\"Mark Zuckerberg criou o Facebook enquanto estudava em Harvard.\"\n",
      "Análise de Relacionamento:\n",
      "{\n",
      "  \"entidade1\": \"Mark Zuckerberg\",\n",
      "  \"entidade2\": \"Facebook\",\n",
      "  \"relacionamento\": \"criou\"\n",
      "}\n",
      "\n",
      "Texto:\n",
      "\"Jeff Bezos fundou a Amazon em 1994 e transformou-a numa das maiores empresas de comércio eletrônico do mundo.\"\n",
      "Análise de Relacionamento:\n",
      "{\n",
      "  \"entidade1\": \"Jeff Bezos\",\n",
      "  \"entidade2\": \"Amazon\",\n",
      "  \"relacionamento\": \"fundou\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "Q: \n",
      "Elon Musk fundou a SpaceX em 2002 com o objetivo de reduzir os custos de transporte espacial e possibilitar a colonização de Marte.\n",
      "\n",
      "Analise a frase e extraia o relacionamento entre duas entidades e, em seguida, produza os resultados indicando: entities e relatiohships entre estas no formato JSON\n",
      "\n",
      "A:\n",
      "{\n",
      "  \"entidade1\": \"Elon Musk\",\n",
      "  \"entidade2\": \"SpaceX\",\n",
      "  \"relacionamento\": \"fundou\"\n",
      "}\n",
      "\n",
      "{\n",
      "  \"entidade1\": \"SpaceX\",\n",
      "  \"entidade2\": \"reduzir os custos de transporte espacial\",\n",
      "  \"relacionamento\": \"objetivo de\"\n",
      "}\n",
      "\n",
      "{\n",
      "  \"entidade1\": \"SpaceX\",\n",
      "  \"entidade2\": \"colonização de Marte\",\n",
      "  \"relacionamento\": \"objetivo de\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "################# Extração de Relações #################\n",
    "\n",
    "\n",
    "context = \"\"\"\n",
    "Texto:\n",
    "\"Mark Zuckerberg criou o Facebook enquanto estudava em Harvard.\"\n",
    "Análise de Relacionamento:\n",
    "{\n",
    "  \"entidade1\": \"Mark Zuckerberg\",\n",
    "  \"entidade2\": \"Facebook\",\n",
    "  \"relacionamento\": \"criou\"\n",
    "}\n",
    "\n",
    "Texto:\n",
    "\"Jeff Bezos fundou a Amazon em 1994 e transformou-a numa das maiores empresas de comércio eletrônico do mundo.\"\n",
    "Análise de Relacionamento:\n",
    "{\n",
    "  \"entidade1\": \"Jeff Bezos\",\n",
    "  \"entidade2\": \"Amazon\",\n",
    "  \"relacionamento\": \"fundou\"\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Elon Musk fundou a SpaceX em 2002 com o objetivo de reduzir os custos de transporte espacial e possibilitar a colonização de Marte.\n",
    "\n",
    "Analise a frase e extraia o relacionamento entre duas entidades e, em seguida, produza os resultados indicando: entities e relatiohships entre estas no formato JSON\n",
    "\"\"\"\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Extrair os tensores de input_ids e da attention_mask\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "input_ids = input_ids.to('cuda')\n",
    "attention_mask = tokens[\"attention_mask\"]\n",
    "\n",
    "# Outputs - Passar ambos para o modelo e gerar a resposta (generate_ids = outputs)\n",
    "with torch.no_grad():\n",
    "    generate_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=256,\n",
    "        #do_sample=True,\n",
    "        #top_k=40,\n",
    "    )\n",
    "\n",
    "# Decodificação e impressão da resposta (answer = last_hidden_states)\n",
    "last_hidden_states = tokenizer.decode(generate_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "answer = last_hidden_states\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
